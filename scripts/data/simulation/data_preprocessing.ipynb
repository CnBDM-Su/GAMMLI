{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.11543722  4.91853929 11.17624764 ...  3.93190744 17.9309684\n",
      "  16.99133486]\n",
      " [ 5.52978497  8.00198594  7.47153809 ...  8.36153068  4.87766179\n",
      "   4.6576346 ]\n",
      " [ 6.77306402  2.99561535  9.8204663  ...  2.30691438 11.52009062\n",
      "  10.97671608]\n",
      " ...\n",
      " [10.66664316 14.75199909 13.7965958  ... 14.33173802 16.3550069\n",
      "  15.4749298 ]\n",
      " [ 2.75340956  1.04324924  5.7059259  ...  1.86860187  9.64693103\n",
      "   9.23106361]\n",
      " [ 4.17390719  2.69391806  7.00289632 ...  4.07243355 10.37411099\n",
      "  10.02865874]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "n_user = 100\n",
    "n_item = 1000\n",
    "n_rank = 10\n",
    "n_user_group = 5\n",
    "n_item_group = 10\n",
    "n_user_feature = 5\n",
    "n_item_feature = 5\n",
    "noise_sigma = 0.01\n",
    "\n",
    "## MF part\n",
    "user_id, user_group = make_blobs(n_samples=n_user, centers=n_user_group, n_features=n_rank,\n",
    "                  cluster_std=0.1, center_box=(-1, 1), random_state=0)\n",
    "item_id, item_group = make_blobs(n_samples=n_item, centers=n_item_group, n_features=n_rank,\n",
    "                  cluster_std=0.1, center_box=(-1, 1), random_state=1)\n",
    "full_matrix_mf = np.tensordot(user_id, item_id, axes=[1, 1])\n",
    "\n",
    "## user item features\n",
    "np.random.seed(1)\n",
    "user_feature = np.random.uniform(0, 1, (n_user, n_user_feature))\n",
    "np.random.seed(0)\n",
    "item_feature = np.random.uniform(0, 1, (n_item, n_item_feature))\n",
    "\n",
    "inter_i1_u2=[]\n",
    "for i,j in product(user_feature[:,2],item_feature[:,1]):\n",
    "    inter_i1_u2.append(0.5*np.exp(-4*(i+j)+4))\n",
    "inter_i1_u2 = np.array(inter_i1_u2).reshape(n_user,n_item)\n",
    "\n",
    "inter_i2_u1=[]\n",
    "for i,j in product(user_feature[:,1],item_feature[:,2]):\n",
    "    inter_i2_u1.append(5*np.sin(2*np.pi*i*j))\n",
    "inter_i2_u1 = np.array(inter_i2_u1).reshape(n_user,n_item)\n",
    "full_matrix_feature =  5 * user_feature[:, 0].reshape(-1,1) +  (5 * item_feature[:, 0] ** 2).reshape(1,-1) + inter_i1_u2 + inter_i2_u1\n",
    "\n",
    "# full matrix\n",
    "np.random.seed(0)\n",
    "full_matrix = 0.1*full_matrix_mf + full_matrix_feature + noise_sigma * np.random.normal(0, 1, (n_user, n_item))\n",
    "print(full_matrix)\n",
    "binary_full_matrix = 1.0 * (full_matrix > 0).astype(int)\n",
    "\n",
    "missing_rate = 0.9\n",
    "np.random.seed(0)\n",
    "input_mask_data = np.random.uniform(0, 1, binary_full_matrix.shape)\n",
    "binary_full_matrix[input_mask_data <= missing_rate] = np.nan\n",
    "full_matrix[np.isnan(binary_full_matrix)]=np.nan\n",
    "\n",
    "pair = []\n",
    "for i in range(full_matrix.shape[0]):\n",
    "    for j in range(full_matrix.shape[1]):\n",
    "        if np.isnan(full_matrix[i,j])==False:\n",
    "            pair.append([i,j,full_matrix[i,j]])\n",
    "            \n",
    "pair = np.array(pair)\n",
    "b= range(user_feature.shape[0])\n",
    "user_feature = np.insert(user_feature, 0, values=b, axis=1)\n",
    "\n",
    "b= range(item_feature.shape[0])\n",
    "item_feature = np.insert(item_feature, 0, values=b, axis=1)\n",
    "\n",
    "user_feature_d = pd.DataFrame(user_feature,columns=['u_id','uf_1','uf_2','uf_3','uf_4','uf_5'])\n",
    "item_feature_d = pd.DataFrame(item_feature,columns=['i_id','if_1','if_2','if_3','if_4','if_5'])\n",
    "\n",
    "pair_d = pd.DataFrame(pair,columns=['user_id','item_id','target'])\n",
    "\n",
    "pu=  pd.merge(pair_d,user_feature_d,left_on='user_id',right_on='u_id')\n",
    "puv=  pd.merge(pu,item_feature_d,left_on='item_id',right_on='i_id')\n",
    "puv.drop(['u_id','i_id'],1,inplace=True)\n",
    "\n",
    "target = puv.target\n",
    "user_id = puv.user_id\n",
    "item_id = puv.item_id\n",
    "data = puv.drop(['target','user_id','item_id'],1)\n",
    "data = pd.concat([data,user_id,item_id,target],1)\n",
    "\n",
    "data.to_csv('sim_0.9.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "n_user = 100\n",
    "n_item = 1000\n",
    "n_rank = 10\n",
    "n_user_group = 5\n",
    "n_item_group = 10\n",
    "n_user_feature = 5\n",
    "n_item_feature = 5\n",
    "noise_sigma = 0.01\n",
    "\n",
    "## MF part\n",
    "user_id, user_group = make_blobs(n_samples=n_user, centers=n_user_group, n_features=n_rank,\n",
    "                  cluster_std=0.1, center_box=(-1, 1), random_state=0)\n",
    "item_id, item_group = make_blobs(n_samples=n_item, centers=n_item_group, n_features=n_rank,\n",
    "                  cluster_std=0.1, center_box=(-1, 1), random_state=1)\n",
    "full_matrix_mf = np.tensordot(user_id, item_id, axes=[1, 1])\n",
    "\n",
    "## user item features\n",
    "np.random.seed(1)\n",
    "user_feature = np.random.uniform(0, 1, (n_user, n_user_feature))\n",
    "np.random.seed(0)\n",
    "item_feature = np.random.uniform(0, 1, (n_item, n_item_feature))\n",
    "\n",
    "inter_i1_u2=[]\n",
    "for i,j in product(user_feature[:,2],item_feature[:,1]):\n",
    "    inter_i1_u2.append(0.5*np.exp(-4*(i+j)+4))\n",
    "inter_i1_u2 = np.array(inter_i1_u2).reshape(n_user,n_item)\n",
    "\n",
    "inter_i2_u1=[]\n",
    "for i,j in product(user_feature[:,1],item_feature[:,2]):\n",
    "    inter_i2_u1.append(5*np.sin(2*np.pi*i*j))\n",
    "inter_i2_u1 = np.array(inter_i2_u1).reshape(n_user,n_item)\n",
    "full_matrix_feature =  5 * user_feature[:, 0].reshape(-1,1) +  (5 * item_feature[:, 0] ** 2).reshape(1,-1) + inter_i1_u2 + inter_i2_u1\n",
    "\n",
    "'''\n",
    "user_feature_effect = 5 * user_feature[:, 0] + 0.5 * np.exp(-4 * (user_feature[:, 1] + user_feature[:, 2]) + 4)\n",
    "item_feature_effect = 5 * item_feature[:, 0] ** 2 + 5 * np.sin(2 * np.pi * item_feature[:, 1] * item_feature[:, 2] )\n",
    "full_matrix_feature = user_feature_effect.reshape(-1, 1) + item_feature_effect.reshape(1, -1)\n",
    "'''\n",
    "# full matrix\n",
    "np.random.seed(0)\n",
    "full_matrix = 10*full_matrix_mf + full_matrix_feature + noise_sigma * np.random.normal(0, 1, (n_user, n_item))\n",
    "\n",
    "binary_full_matrix = 1.0 * (full_matrix > 0).astype(int)\n",
    "\n",
    "model = MinMaxScaler()\n",
    "full_matrix = model.fit_transform(full_matrix.T).T\n",
    "\n",
    "full_matrix[full_matrix>=0.5]=1\n",
    "full_matrix[full_matrix<0.5]=0\n",
    "\n",
    "full_matrix[full_matrix<0]=0\n",
    "full_matrix[full_matrix>1]=1\n",
    "\n",
    "missing_rate = 0.9\n",
    "np.random.seed(0)\n",
    "input_mask_data = np.random.uniform(0, 1, binary_full_matrix.shape)\n",
    "binary_full_matrix[input_mask_data <= missing_rate] = np.nan\n",
    "full_matrix[np.isnan(binary_full_matrix)]=np.nan\n",
    "\n",
    "pair = []\n",
    "for i in range(full_matrix.shape[0]):\n",
    "    for j in range(full_matrix.shape[1]):\n",
    "        if np.isnan(full_matrix[i,j])==False:\n",
    "            pair.append([i,j,full_matrix[i,j]])\n",
    "            \n",
    "pair = np.array(pair)\n",
    "b= range(user_feature.shape[0])\n",
    "user_feature = np.insert(user_feature, 0, values=b, axis=1)\n",
    "\n",
    "b= range(item_feature.shape[0])\n",
    "item_feature = np.insert(item_feature, 0, values=b, axis=1)\n",
    "\n",
    "user_feature_d = pd.DataFrame(user_feature,columns=['u_id','uf_1','uf_2','uf_3','uf_4','uf_5'])\n",
    "item_feature_d = pd.DataFrame(item_feature,columns=['i_id','if_1','if_2','if_3','if_4','if_5'])\n",
    "\n",
    "pair_d = pd.DataFrame(pair,columns=['user_id','item_id','target'])\n",
    "\n",
    "pu=  pd.merge(pair_d,user_feature_d,left_on='user_id',right_on='u_id')\n",
    "puv=  pd.merge(pu,item_feature_d,left_on='item_id',right_on='i_id')\n",
    "puv.drop(['u_id','i_id'],1,inplace=True)\n",
    "\n",
    "target = puv.target\n",
    "user_id = puv.user_id\n",
    "item_id = puv.item_id\n",
    "data = puv.drop(['target','user_id','item_id'],1)\n",
    "data = pd.concat([data,user_id,item_id,target],1)\n",
    "\n",
    "data.to_csv('sim_binary_0.9_2.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_matrix[full_matrix>0.43194]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
