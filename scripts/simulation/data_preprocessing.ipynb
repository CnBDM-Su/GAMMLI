{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "n_user = 100\n",
    "n_item = 1000\n",
    "n_rank = 10\n",
    "n_user_group = 5\n",
    "n_item_group = 10\n",
    "n_user_feature = 5\n",
    "n_item_feature = 5\n",
    "noise_sigma = 0.1\n",
    "\n",
    "## MF part\n",
    "user_id, user_group = make_blobs(n_samples=n_user, centers=n_user_group, n_features=n_rank,\n",
    "                  cluster_std=0.1, center_box=(-1, 1), random_state=0)\n",
    "item_id, item_group = make_blobs(n_samples=n_item, centers=n_item_group, n_features=n_rank,\n",
    "                  cluster_std=0.1, center_box=(-1, 1), random_state=1)\n",
    "full_matrix_mf = np.tensordot(user_id, item_id, axes=[1, 1])\n",
    "\n",
    "## user item features\n",
    "np.random.seed(0)\n",
    "user_feature = np.random.uniform(0, 1, (n_user, n_user_feature))\n",
    "np.random.seed(0)\n",
    "item_feature = np.random.uniform(0, 1, (n_item, n_item_feature))\n",
    "\n",
    "user_feature_effect = 1.5 * user_feature[:, 0] + 0.5 * np.exp(-4 * (user_feature[:, 1] + user_feature[:, 2]) + 4)\n",
    "item_feature_effect = 2 * item_feature[:, 0] ** 2 + 5 * np.sin(2 * np.pi * item_feature[:, 1] * item_feature[:, 2] )\n",
    "full_matrix_feature = user_feature_effect.reshape(-1, 1) + item_feature_effect.reshape(1, -1)\n",
    "\n",
    "# full matrix\n",
    "np.random.seed(0)\n",
    "full_matrix = full_matrix_mf + full_matrix_feature + noise_sigma * np.random.normal(0, 1, (n_user, n_item))\n",
    "print(full_matrix)\n",
    "binary_full_matrix = 1.0 * (full_matrix > 0).astype(int)\n",
    "\n",
    "user_position = pd.DataFrame(user_id,columns=['up_1','up_2','up_3','up_4','up_5','up_6','up_7','up_8','up_9','up_10'])\n",
    "item_position = pd.DataFrame(item_id,columns=['ip_1','ip_2','ip_3','ip_4','ip_5','ip_6','ip_7','ip_8','ip_9','ip_10'])\n",
    "user_group = pd.DataFrame(user_group,columns=['user_group'])\n",
    "item_group = pd.DataFrame(item_group,columns=['item_group'])\n",
    "user_group.to_csv('data/simulation/user_group.csv',index=None)\n",
    "item_group.to_csv('data/simulation/item_group.csv',index=None)\n",
    "user_position.to_csv('data/simulation/user_pos.csv',index=None)\n",
    "item_position.to_csv('data/simulation/item_pos.csv',index=None)\n",
    "\n",
    "missing_rate = 0.1\n",
    "np.random.seed(0)\n",
    "input_mask_data = np.random.uniform(0, 1, binary_full_matrix.shape)\n",
    "binary_full_matrix[input_mask_data <= missing_rate] = np.nan\n",
    "full_matrix[np.isnan(binary_full_matrix)]=np.nan\n",
    "\n",
    "pair = []\n",
    "for i in range(full_matrix.shape[0]):\n",
    "    for j in range(full_matrix.shape[1]):\n",
    "        if np.isnan(full_matrix[i,j])==False:\n",
    "            pair.append([i,j,full_matrix[i,j]])\n",
    "            \n",
    "pair = np.array(pair)\n",
    "b= range(user_feature.shape[0])\n",
    "user_feature = np.insert(user_feature, 0, values=b, axis=1)\n",
    "\n",
    "b= range(item_feature.shape[0])\n",
    "item_feature = np.insert(item_feature, 0, values=b, axis=1)\n",
    "\n",
    "user_feature_d = pd.DataFrame(user_feature,columns=['u_id','uf_1','uf_2','uf_3','uf_4','uf_5'])\n",
    "item_feature_d = pd.DataFrame(item_feature,columns=['i_id','if_1','if_2','if_3','if_4','if_5'])\n",
    "\n",
    "pair_d = pd.DataFrame(pair,columns=['user_id','item_id','target'])\n",
    "\n",
    "pu=  pd.merge(pair_d,user_feature_d,left_on='user_id',right_on='u_id')\n",
    "puv=  pd.merge(pu,item_feature_d,left_on='item_id',right_on='i_id')\n",
    "puv.drop(['u_id','i_id'],1,inplace=True)\n",
    "\n",
    "target = puv.target\n",
    "user_id = puv.user_id\n",
    "item_id = puv.item_id\n",
    "data = puv.drop(['target','user_id','item_id'],1)\n",
    "data = pd.concat([data,user_id,item_id,target],1)\n",
    "\n",
    "data.to_csv('data/simulation/sim_0.1.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "n_user = 100\n",
    "n_item = 1000\n",
    "n_rank = 10\n",
    "n_user_group = 5\n",
    "n_item_group = 10\n",
    "n_user_feature = 5\n",
    "n_item_feature = 5\n",
    "noise_sigma = 0.1\n",
    "\n",
    "## MF part\n",
    "user_id, user_group = make_blobs(n_samples=n_user, centers=n_user_group, n_features=n_rank,\n",
    "                  cluster_std=0.1, center_box=(-1, 1), random_state=0)\n",
    "item_id, item_group = make_blobs(n_samples=n_item, centers=n_item_group, n_features=n_rank,\n",
    "                  cluster_std=0.1, center_box=(-1, 1), random_state=1)\n",
    "full_matrix_mf = np.tensordot(user_id, item_id, axes=[1, 1])\n",
    "\n",
    "## user item features\n",
    "np.random.seed(0)\n",
    "user_feature = np.random.uniform(0, 1, (n_user, n_user_feature))\n",
    "np.random.seed(0)\n",
    "item_feature = np.random.uniform(0, 1, (n_item, n_item_feature))\n",
    "\n",
    "user_feature_effect = 1.5 * user_feature[:, 0] + 0.5 * np.exp(-4 * (user_feature[:, 1] + user_feature[:, 2]) + 4)\n",
    "item_feature_effect = 2 * item_feature[:, 0] ** 2 + 5 * np.sin(2 * np.pi * item_feature[:, 1] * item_feature[:, 2] )\n",
    "full_matrix_feature = user_feature_effect.reshape(-1, 1) + item_feature_effect.reshape(1, -1)\n",
    "\n",
    "# full matrix\n",
    "np.random.seed(0)\n",
    "full_matrix = full_matrix_mf + full_matrix_feature + noise_sigma * np.random.normal(0, 1, (n_user, n_item))\n",
    "\n",
    "binary_full_matrix = 1.0 * (full_matrix > 0).astype(int)\n",
    "\n",
    "model = MinMaxScaler()\n",
    "full_matrix = model.fit_transform(full_matrix.T).T\n",
    "\n",
    "full_matrix[full_matrix>=0.6]=1\n",
    "full_matrix[full_matrix<0.6]=0\n",
    "\n",
    "full_matrix[full_matrix<0]=0\n",
    "full_matrix[full_matrix>1]=1\n",
    "\n",
    "# p_0 = 1- full_matrix\n",
    "# for i in range(full_matrix.shape[0]):\n",
    "#     for j in range(full_matrix.shape[1]):\n",
    "#         full_matrix[i][j] = np.random.choice([0,1],p=np.array([full_matrix[i][j],p_0[i][j]]).ravel())\n",
    "        \n",
    "\n",
    "user_position = pd.DataFrame(user_id,columns=['up_1','up_2','up_3','up_4','up_5','up_6','up_7','up_8','up_9','up_10'])\n",
    "item_position = pd.DataFrame(item_id,columns=['ip_1','ip_2','ip_3','ip_4','ip_5','ip_6','ip_7','ip_8','ip_9','ip_10'])\n",
    "user_group = pd.DataFrame(user_group,columns=['user_group'])\n",
    "item_group = pd.DataFrame(item_group,columns=['item_group'])\n",
    "user_group.to_csv('data/simulation/user_group.csv',index=None)\n",
    "item_group.to_csv('data/simulation/item_group.csv',index=None)\n",
    "user_position.to_csv('data/simulation/user_pos.csv',index=None)\n",
    "item_position.to_csv('data/simulation/item_pos.csv',index=None)\n",
    "\n",
    "missing_rate = 0.9\n",
    "np.random.seed(0)\n",
    "input_mask_data = np.random.uniform(0, 1, binary_full_matrix.shape)\n",
    "binary_full_matrix[input_mask_data <= missing_rate] = np.nan\n",
    "full_matrix[np.isnan(binary_full_matrix)]=np.nan\n",
    "\n",
    "pair = []\n",
    "for i in range(full_matrix.shape[0]):\n",
    "    for j in range(full_matrix.shape[1]):\n",
    "        if np.isnan(full_matrix[i,j])==False:\n",
    "            pair.append([i,j,full_matrix[i,j]])\n",
    "            \n",
    "pair = np.array(pair)\n",
    "b= range(user_feature.shape[0])\n",
    "user_feature = np.insert(user_feature, 0, values=b, axis=1)\n",
    "\n",
    "b= range(item_feature.shape[0])\n",
    "item_feature = np.insert(item_feature, 0, values=b, axis=1)\n",
    "\n",
    "user_feature_d = pd.DataFrame(user_feature,columns=['u_id','uf_1','uf_2','uf_3','uf_4','uf_5'])\n",
    "item_feature_d = pd.DataFrame(item_feature,columns=['i_id','if_1','if_2','if_3','if_4','if_5'])\n",
    "\n",
    "pair_d = pd.DataFrame(pair,columns=['user_id','item_id','target'])\n",
    "\n",
    "pu=  pd.merge(pair_d,user_feature_d,left_on='user_id',right_on='u_id')\n",
    "puv=  pd.merge(pu,item_feature_d,left_on='item_id',right_on='i_id')\n",
    "puv.drop(['u_id','i_id'],1,inplace=True)\n",
    "\n",
    "target = puv.target\n",
    "user_id = puv.user_id\n",
    "item_id = puv.item_id\n",
    "data = puv.drop(['target','user_id','item_id'],1)\n",
    "data = pd.concat([data,user_id,item_id,target],1)\n",
    "\n",
    "data.to_csv('data/simulation/sim_binary_0.9_2.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
