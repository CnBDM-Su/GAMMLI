{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LVXNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 146.52 MB\n",
      "Memory usage after optimization is: 19.84 MB\n",
      "Decreased by 86.5%\n",
      "Memory usage of dataframe is 36.63 MB\n",
      "Memory usage after optimization is: 4.96 MB\n",
      "Decreased by 86.5%\n",
      "cold start user: 3086\n",
      "cold start item: 1964\n",
      "0\n",
      "ListWrapper(['Gender', 'Age', 'Occupation', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.89224, val loss: 0.88902\n",
      "Main effects training epoch: 2, train loss: 0.87938, val loss: 0.87646\n",
      "Main effects training epoch: 3, train loss: 0.87468, val loss: 0.87161\n",
      "Main effects training epoch: 4, train loss: 0.87453, val loss: 0.87135\n",
      "Main effects training epoch: 5, train loss: 0.86936, val loss: 0.86602\n",
      "Main effects training epoch: 6, train loss: 0.87035, val loss: 0.86703\n",
      "Main effects training epoch: 7, train loss: 0.86673, val loss: 0.86331\n",
      "Main effects training epoch: 8, train loss: 0.86564, val loss: 0.86217\n",
      "Main effects training epoch: 9, train loss: 0.86609, val loss: 0.86266\n",
      "Main effects training epoch: 10, train loss: 0.86437, val loss: 0.86088\n",
      "Main effects training epoch: 11, train loss: 0.86536, val loss: 0.86192\n",
      "Main effects training epoch: 12, train loss: 0.86385, val loss: 0.86038\n",
      "Main effects training epoch: 13, train loss: 0.86354, val loss: 0.86006\n",
      "Main effects training epoch: 14, train loss: 0.86382, val loss: 0.86037\n",
      "Main effects training epoch: 15, train loss: 0.86374, val loss: 0.86029\n",
      "Main effects training epoch: 16, train loss: 0.86372, val loss: 0.86027\n",
      "Main effects training epoch: 17, train loss: 0.86329, val loss: 0.85984\n",
      "Main effects training epoch: 18, train loss: 0.86313, val loss: 0.85968\n",
      "Main effects training epoch: 19, train loss: 0.86302, val loss: 0.85957\n",
      "Main effects training epoch: 20, train loss: 0.86345, val loss: 0.85999\n",
      "##########Stage 1: main effect training stop.##########\n",
      "19 main effects are pruned, start tuning.##########\n",
      "Main effects tuning epoch: 1, train loss: 0.86580, val loss: 0.86235\n",
      "Main effects tuning epoch: 2, train loss: 0.86511, val loss: 0.86167\n",
      "Main effects tuning epoch: 3, train loss: 0.86357, val loss: 0.86015\n",
      "Main effects tuning epoch: 4, train loss: 0.86352, val loss: 0.86010\n",
      "Main effects tuning epoch: 5, train loss: 0.86275, val loss: 0.85931\n",
      "Main effects tuning epoch: 6, train loss: 0.86284, val loss: 0.85940\n",
      "Main effects tuning epoch: 7, train loss: 0.86371, val loss: 0.86030\n",
      "Main effects tuning epoch: 8, train loss: 0.86291, val loss: 0.85947\n",
      "Main effects tuning epoch: 9, train loss: 0.86303, val loss: 0.85961\n",
      "Main effects tuning epoch: 10, train loss: 0.86355, val loss: 0.86013\n",
      "Main effects tuning epoch: 11, train loss: 0.86348, val loss: 0.86006\n",
      "Main effects tuning epoch: 12, train loss: 0.86305, val loss: 0.85961\n",
      "Main effects tuning epoch: 13, train loss: 0.86325, val loss: 0.85981\n",
      "Main effects tuning epoch: 14, train loss: 0.86433, val loss: 0.86089\n",
      "Main effects tuning epoch: 15, train loss: 0.86495, val loss: 0.86156\n",
      "Main effects tuning epoch: 16, train loss: 0.86283, val loss: 0.85940\n",
      "Main effects tuning epoch: 17, train loss: 0.86340, val loss: 0.85998\n",
      "Main effects tuning epoch: 18, train loss: 0.86353, val loss: 0.86011\n",
      "Main effects tuning epoch: 19, train loss: 0.86366, val loss: 0.86022\n",
      "Main effects tuning epoch: 20, train loss: 0.86450, val loss: 0.86110\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.86285, val loss: 0.85941\n",
      "Interaction training epoch: 2, train loss: 0.86343, val loss: 0.86002\n",
      "Interaction training epoch: 3, train loss: 0.86272, val loss: 0.85928\n",
      "Interaction training epoch: 4, train loss: 0.86282, val loss: 0.85939\n",
      "Interaction training epoch: 5, train loss: 0.86282, val loss: 0.85939\n",
      "Interaction training epoch: 6, train loss: 0.86272, val loss: 0.85929\n",
      "Interaction training epoch: 7, train loss: 0.86310, val loss: 0.85966\n",
      "Interaction training epoch: 8, train loss: 0.86300, val loss: 0.85957\n",
      "Interaction training epoch: 9, train loss: 0.86284, val loss: 0.85941\n",
      "Interaction training epoch: 10, train loss: 0.86276, val loss: 0.85932\n",
      "Interaction training epoch: 11, train loss: 0.86277, val loss: 0.85933\n",
      "Interaction training epoch: 12, train loss: 0.86289, val loss: 0.85945\n",
      "Interaction training epoch: 13, train loss: 0.86280, val loss: 0.85936\n",
      "Interaction training epoch: 14, train loss: 0.86286, val loss: 0.85943\n",
      "Interaction training epoch: 15, train loss: 0.86270, val loss: 0.85926\n",
      "Interaction training epoch: 16, train loss: 0.86282, val loss: 0.85939\n",
      "Interaction training epoch: 17, train loss: 0.86269, val loss: 0.85925\n",
      "Interaction training epoch: 18, train loss: 0.86336, val loss: 0.85994\n",
      "Interaction training epoch: 19, train loss: 0.86272, val loss: 0.85928\n",
      "Interaction training epoch: 20, train loss: 0.86285, val loss: 0.85941\n",
      "##########Stage 2: interaction training stop.##########\n",
      "##########No interaction is selected, the model returns to GAM.##########\n",
      "####################GAMI-Net training finished.####################\n",
      "time cost: 259.11711835861206\n",
      "After the gam stage, training error is 0.86450 , validation error is 0.86110\n",
      "missing value counts: 21521014\n",
      "[SoftImpute] Max Singular Value of X_init = 236.847305\n",
      "#####mf_training#####\n",
      "[SoftImpute] Iter 1: observed MAE=0.812222 validation MAE=0.816724,rank=3\n",
      "[SoftImpute] Iter 2: observed MAE=0.796499 validation MAE=0.802696,rank=3\n",
      "[SoftImpute] Iter 3: observed MAE=0.783839 validation MAE=0.791175,rank=3\n",
      "[SoftImpute] Iter 4: observed MAE=0.773510 validation MAE=0.781668,rank=3\n",
      "[SoftImpute] Iter 5: observed MAE=0.765018 validation MAE=0.773882,rank=3\n",
      "[SoftImpute] Iter 6: observed MAE=0.758017 validation MAE=0.767508,rank=3\n",
      "[SoftImpute] Iter 7: observed MAE=0.752165 validation MAE=0.762227,rank=3\n",
      "[SoftImpute] Iter 8: observed MAE=0.747207 validation MAE=0.757797,rank=3\n",
      "[SoftImpute] Iter 9: observed MAE=0.742953 validation MAE=0.754042,rank=3\n",
      "[SoftImpute] Iter 10: observed MAE=0.739260 validation MAE=0.750818,rank=3\n",
      "[SoftImpute] Iter 11: observed MAE=0.736020 validation MAE=0.748011,rank=3\n",
      "[SoftImpute] Iter 12: observed MAE=0.733151 validation MAE=0.745534,rank=3\n",
      "[SoftImpute] Iter 13: observed MAE=0.730587 validation MAE=0.743331,rank=3\n",
      "[SoftImpute] Iter 14: observed MAE=0.728283 validation MAE=0.741366,rank=3\n",
      "[SoftImpute] Iter 15: observed MAE=0.726200 validation MAE=0.739600,rank=3\n",
      "[SoftImpute] Iter 16: observed MAE=0.724305 validation MAE=0.738006,rank=3\n",
      "[SoftImpute] Iter 17: observed MAE=0.722571 validation MAE=0.736554,rank=3\n",
      "[SoftImpute] Iter 18: observed MAE=0.720978 validation MAE=0.735225,rank=3\n",
      "[SoftImpute] Iter 19: observed MAE=0.719506 validation MAE=0.734010,rank=3\n",
      "[SoftImpute] Iter 20: observed MAE=0.718144 validation MAE=0.732894,rank=3\n",
      "[SoftImpute] Iter 21: observed MAE=0.716880 validation MAE=0.731862,rank=3\n",
      "[SoftImpute] Iter 22: observed MAE=0.715701 validation MAE=0.730906,rank=3\n",
      "[SoftImpute] Iter 23: observed MAE=0.714597 validation MAE=0.730021,rank=3\n",
      "[SoftImpute] Iter 24: observed MAE=0.713562 validation MAE=0.729193,rank=3\n",
      "[SoftImpute] Iter 25: observed MAE=0.712588 validation MAE=0.728416,rank=3\n",
      "[SoftImpute] Iter 26: observed MAE=0.711669 validation MAE=0.727686,rank=3\n",
      "[SoftImpute] Iter 27: observed MAE=0.710799 validation MAE=0.726999,rank=3\n",
      "[SoftImpute] Iter 28: observed MAE=0.709975 validation MAE=0.726352,rank=3\n",
      "[SoftImpute] Iter 29: observed MAE=0.709194 validation MAE=0.725741,rank=3\n",
      "[SoftImpute] Iter 30: observed MAE=0.708450 validation MAE=0.725160,rank=3\n",
      "[SoftImpute] Iter 31: observed MAE=0.707741 validation MAE=0.724608,rank=3\n",
      "[SoftImpute] Iter 32: observed MAE=0.707065 validation MAE=0.724084,rank=3\n",
      "[SoftImpute] Iter 33: observed MAE=0.706420 validation MAE=0.723585,rank=3\n",
      "[SoftImpute] Iter 34: observed MAE=0.705803 validation MAE=0.723112,rank=3\n",
      "[SoftImpute] Iter 35: observed MAE=0.705212 validation MAE=0.722659,rank=3\n",
      "[SoftImpute] Iter 36: observed MAE=0.704644 validation MAE=0.722225,rank=3\n",
      "[SoftImpute] Iter 37: observed MAE=0.704099 validation MAE=0.721810,rank=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 38: observed MAE=0.703574 validation MAE=0.721410,rank=3\n",
      "[SoftImpute] Iter 39: observed MAE=0.703069 validation MAE=0.721027,rank=3\n",
      "[SoftImpute] Iter 40: observed MAE=0.702581 validation MAE=0.720657,rank=3\n",
      "[SoftImpute] Iter 41: observed MAE=0.702111 validation MAE=0.720302,rank=3\n",
      "[SoftImpute] Iter 42: observed MAE=0.701656 validation MAE=0.719959,rank=3\n",
      "[SoftImpute] Iter 43: observed MAE=0.701216 validation MAE=0.719629,rank=3\n",
      "[SoftImpute] Iter 44: observed MAE=0.700789 validation MAE=0.719310,rank=3\n",
      "[SoftImpute] Iter 45: observed MAE=0.700376 validation MAE=0.719001,rank=3\n",
      "[SoftImpute] Iter 46: observed MAE=0.699976 validation MAE=0.718702,rank=3\n",
      "[SoftImpute] Iter 47: observed MAE=0.699587 validation MAE=0.718413,rank=3\n",
      "[SoftImpute] Iter 48: observed MAE=0.699210 validation MAE=0.718131,rank=3\n",
      "[SoftImpute] Iter 49: observed MAE=0.698843 validation MAE=0.717857,rank=3\n",
      "[SoftImpute] Iter 50: observed MAE=0.698486 validation MAE=0.717590,rank=3\n",
      "[SoftImpute] Iter 51: observed MAE=0.698138 validation MAE=0.717330,rank=3\n",
      "[SoftImpute] Iter 52: observed MAE=0.697800 validation MAE=0.717076,rank=3\n",
      "[SoftImpute] Iter 53: observed MAE=0.697470 validation MAE=0.716830,rank=3\n",
      "[SoftImpute] Iter 54: observed MAE=0.697149 validation MAE=0.716590,rank=3\n",
      "[SoftImpute] Iter 55: observed MAE=0.696835 validation MAE=0.716357,rank=3\n",
      "[SoftImpute] Iter 56: observed MAE=0.696528 validation MAE=0.716129,rank=3\n",
      "[SoftImpute] Iter 57: observed MAE=0.696229 validation MAE=0.715907,rank=3\n",
      "[SoftImpute] Iter 58: observed MAE=0.695936 validation MAE=0.715689,rank=3\n",
      "[SoftImpute] Iter 59: observed MAE=0.695651 validation MAE=0.715477,rank=3\n",
      "[SoftImpute] Iter 60: observed MAE=0.695371 validation MAE=0.715269,rank=3\n",
      "[SoftImpute] Iter 61: observed MAE=0.695098 validation MAE=0.715066,rank=3\n",
      "[SoftImpute] Iter 62: observed MAE=0.694830 validation MAE=0.714867,rank=3\n",
      "[SoftImpute] Iter 63: observed MAE=0.694568 validation MAE=0.714674,rank=3\n",
      "[SoftImpute] Iter 64: observed MAE=0.694310 validation MAE=0.714484,rank=3\n",
      "[SoftImpute] Iter 65: observed MAE=0.694058 validation MAE=0.714298,rank=3\n",
      "[SoftImpute] Iter 66: observed MAE=0.693811 validation MAE=0.714115,rank=3\n",
      "[SoftImpute] Iter 67: observed MAE=0.693568 validation MAE=0.713935,rank=3\n",
      "[SoftImpute] Iter 68: observed MAE=0.693329 validation MAE=0.713760,rank=3\n",
      "[SoftImpute] Iter 69: observed MAE=0.693095 validation MAE=0.713588,rank=3\n",
      "[SoftImpute] Iter 70: observed MAE=0.692865 validation MAE=0.713419,rank=3\n",
      "[SoftImpute] Iter 71: observed MAE=0.692639 validation MAE=0.713253,rank=3\n",
      "[SoftImpute] Iter 72: observed MAE=0.692417 validation MAE=0.713089,rank=3\n",
      "[SoftImpute] Iter 73: observed MAE=0.692199 validation MAE=0.712928,rank=3\n",
      "[SoftImpute] Iter 74: observed MAE=0.691984 validation MAE=0.712769,rank=3\n",
      "[SoftImpute] Iter 75: observed MAE=0.691772 validation MAE=0.712613,rank=3\n",
      "[SoftImpute] Iter 76: observed MAE=0.691564 validation MAE=0.712458,rank=3\n",
      "[SoftImpute] Iter 77: observed MAE=0.691359 validation MAE=0.712306,rank=3\n",
      "[SoftImpute] Iter 78: observed MAE=0.691157 validation MAE=0.712156,rank=3\n",
      "[SoftImpute] Iter 79: observed MAE=0.690959 validation MAE=0.712008,rank=3\n",
      "[SoftImpute] Iter 80: observed MAE=0.690763 validation MAE=0.711862,rank=3\n",
      "[SoftImpute] Iter 81: observed MAE=0.690570 validation MAE=0.711717,rank=3\n",
      "[SoftImpute] Iter 82: observed MAE=0.690381 validation MAE=0.711575,rank=3\n",
      "[SoftImpute] Iter 83: observed MAE=0.690194 validation MAE=0.711435,rank=3\n",
      "[SoftImpute] Iter 84: observed MAE=0.690010 validation MAE=0.711297,rank=3\n",
      "[SoftImpute] Iter 85: observed MAE=0.689828 validation MAE=0.711160,rank=3\n",
      "[SoftImpute] Iter 86: observed MAE=0.689649 validation MAE=0.711024,rank=3\n",
      "[SoftImpute] Iter 87: observed MAE=0.689473 validation MAE=0.710891,rank=3\n",
      "[SoftImpute] Iter 88: observed MAE=0.689299 validation MAE=0.710758,rank=3\n",
      "[SoftImpute] Iter 89: observed MAE=0.689127 validation MAE=0.710627,rank=3\n",
      "[SoftImpute] Iter 90: observed MAE=0.688957 validation MAE=0.710497,rank=3\n",
      "[SoftImpute] Iter 91: observed MAE=0.688790 validation MAE=0.710368,rank=3\n",
      "[SoftImpute] Iter 92: observed MAE=0.688625 validation MAE=0.710240,rank=3\n",
      "[SoftImpute] Iter 93: observed MAE=0.688462 validation MAE=0.710114,rank=3\n",
      "[SoftImpute] Iter 94: observed MAE=0.688302 validation MAE=0.709989,rank=3\n",
      "[SoftImpute] Iter 95: observed MAE=0.688143 validation MAE=0.709866,rank=3\n",
      "[SoftImpute] Iter 96: observed MAE=0.687987 validation MAE=0.709744,rank=3\n",
      "[SoftImpute] Iter 97: observed MAE=0.687833 validation MAE=0.709623,rank=3\n",
      "[SoftImpute] Iter 98: observed MAE=0.687681 validation MAE=0.709504,rank=3\n",
      "[SoftImpute] Iter 99: observed MAE=0.687530 validation MAE=0.709387,rank=3\n",
      "[SoftImpute] Iter 100: observed MAE=0.687381 validation MAE=0.709272,rank=3\n",
      "[SoftImpute] Iter 101: observed MAE=0.687234 validation MAE=0.709157,rank=3\n",
      "[SoftImpute] Iter 102: observed MAE=0.687089 validation MAE=0.709044,rank=3\n",
      "[SoftImpute] Iter 103: observed MAE=0.686946 validation MAE=0.708931,rank=3\n",
      "[SoftImpute] Iter 104: observed MAE=0.686804 validation MAE=0.708819,rank=3\n",
      "[SoftImpute] Iter 105: observed MAE=0.686664 validation MAE=0.708709,rank=3\n",
      "[SoftImpute] Iter 106: observed MAE=0.686525 validation MAE=0.708599,rank=3\n",
      "[SoftImpute] Iter 107: observed MAE=0.686388 validation MAE=0.708491,rank=3\n",
      "[SoftImpute] Iter 108: observed MAE=0.686253 validation MAE=0.708384,rank=3\n",
      "[SoftImpute] Iter 109: observed MAE=0.686119 validation MAE=0.708277,rank=3\n",
      "[SoftImpute] Iter 110: observed MAE=0.685987 validation MAE=0.708171,rank=3\n",
      "[SoftImpute] Iter 111: observed MAE=0.685856 validation MAE=0.708066,rank=3\n",
      "[SoftImpute] Iter 112: observed MAE=0.685726 validation MAE=0.707961,rank=3\n",
      "[SoftImpute] Iter 113: observed MAE=0.685598 validation MAE=0.707858,rank=3\n",
      "[SoftImpute] Iter 114: observed MAE=0.685471 validation MAE=0.707755,rank=3\n",
      "[SoftImpute] Iter 115: observed MAE=0.685346 validation MAE=0.707654,rank=3\n",
      "[SoftImpute] Iter 116: observed MAE=0.685222 validation MAE=0.707554,rank=3\n",
      "[SoftImpute] Iter 117: observed MAE=0.685100 validation MAE=0.707455,rank=3\n",
      "[SoftImpute] Iter 118: observed MAE=0.684978 validation MAE=0.707356,rank=3\n",
      "[SoftImpute] Iter 119: observed MAE=0.684858 validation MAE=0.707258,rank=3\n",
      "[SoftImpute] Iter 120: observed MAE=0.684740 validation MAE=0.707161,rank=3\n",
      "[SoftImpute] Iter 121: observed MAE=0.684622 validation MAE=0.707066,rank=3\n",
      "[SoftImpute] Iter 122: observed MAE=0.684506 validation MAE=0.706971,rank=3\n",
      "[SoftImpute] Iter 123: observed MAE=0.684391 validation MAE=0.706877,rank=3\n",
      "[SoftImpute] Iter 124: observed MAE=0.684278 validation MAE=0.706784,rank=3\n",
      "[SoftImpute] Iter 125: observed MAE=0.684165 validation MAE=0.706692,rank=3\n",
      "[SoftImpute] Iter 126: observed MAE=0.684054 validation MAE=0.706600,rank=3\n",
      "[SoftImpute] Iter 127: observed MAE=0.683944 validation MAE=0.706509,rank=3\n",
      "[SoftImpute] Iter 128: observed MAE=0.683835 validation MAE=0.706420,rank=3\n",
      "[SoftImpute] Iter 129: observed MAE=0.683727 validation MAE=0.706331,rank=3\n",
      "[SoftImpute] Iter 130: observed MAE=0.683621 validation MAE=0.706242,rank=3\n",
      "[SoftImpute] Iter 131: observed MAE=0.683515 validation MAE=0.706155,rank=3\n",
      "[SoftImpute] Iter 132: observed MAE=0.683411 validation MAE=0.706068,rank=3\n",
      "[SoftImpute] Iter 133: observed MAE=0.683307 validation MAE=0.705981,rank=3\n",
      "[SoftImpute] Iter 134: observed MAE=0.683205 validation MAE=0.705896,rank=3\n",
      "[SoftImpute] Iter 135: observed MAE=0.683103 validation MAE=0.705812,rank=3\n",
      "[SoftImpute] Iter 136: observed MAE=0.683003 validation MAE=0.705729,rank=3\n",
      "[SoftImpute] Iter 137: observed MAE=0.682903 validation MAE=0.705647,rank=3\n",
      "[SoftImpute] Iter 138: observed MAE=0.682805 validation MAE=0.705565,rank=3\n",
      "[SoftImpute] Iter 139: observed MAE=0.682707 validation MAE=0.705484,rank=3\n",
      "[SoftImpute] Iter 140: observed MAE=0.682611 validation MAE=0.705403,rank=3\n",
      "[SoftImpute] Iter 141: observed MAE=0.682516 validation MAE=0.705324,rank=3\n",
      "[SoftImpute] Iter 142: observed MAE=0.682421 validation MAE=0.705245,rank=3\n",
      "[SoftImpute] Iter 143: observed MAE=0.682328 validation MAE=0.705167,rank=3\n",
      "[SoftImpute] Iter 144: observed MAE=0.682236 validation MAE=0.705090,rank=3\n",
      "[SoftImpute] Iter 145: observed MAE=0.682144 validation MAE=0.705014,rank=3\n",
      "[SoftImpute] Iter 146: observed MAE=0.682054 validation MAE=0.704938,rank=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 147: observed MAE=0.681964 validation MAE=0.704863,rank=3\n",
      "[SoftImpute] Iter 148: observed MAE=0.681875 validation MAE=0.704789,rank=3\n",
      "[SoftImpute] Iter 149: observed MAE=0.681788 validation MAE=0.704716,rank=3\n",
      "[SoftImpute] Iter 150: observed MAE=0.681701 validation MAE=0.704643,rank=3\n",
      "[SoftImpute] Iter 151: observed MAE=0.681615 validation MAE=0.704570,rank=3\n",
      "[SoftImpute] Iter 152: observed MAE=0.681530 validation MAE=0.704498,rank=3\n",
      "[SoftImpute] Iter 153: observed MAE=0.681445 validation MAE=0.704427,rank=3\n",
      "[SoftImpute] Iter 154: observed MAE=0.681362 validation MAE=0.704356,rank=3\n",
      "[SoftImpute] Iter 155: observed MAE=0.681279 validation MAE=0.704286,rank=3\n",
      "[SoftImpute] Iter 156: observed MAE=0.681197 validation MAE=0.704217,rank=3\n",
      "[SoftImpute] Iter 157: observed MAE=0.681116 validation MAE=0.704148,rank=3\n",
      "[SoftImpute] Iter 158: observed MAE=0.681036 validation MAE=0.704080,rank=3\n",
      "[SoftImpute] Iter 159: observed MAE=0.680956 validation MAE=0.704013,rank=3\n",
      "[SoftImpute] Iter 160: observed MAE=0.680878 validation MAE=0.703946,rank=3\n",
      "[SoftImpute] Iter 161: observed MAE=0.680800 validation MAE=0.703880,rank=3\n",
      "[SoftImpute] Iter 162: observed MAE=0.680723 validation MAE=0.703814,rank=3\n",
      "[SoftImpute] Iter 163: observed MAE=0.680646 validation MAE=0.703749,rank=3\n",
      "[SoftImpute] Iter 164: observed MAE=0.680571 validation MAE=0.703685,rank=3\n",
      "[SoftImpute] Iter 165: observed MAE=0.680496 validation MAE=0.703621,rank=3\n",
      "[SoftImpute] Iter 166: observed MAE=0.680422 validation MAE=0.703557,rank=3\n",
      "[SoftImpute] Iter 167: observed MAE=0.680348 validation MAE=0.703495,rank=3\n",
      "[SoftImpute] Iter 168: observed MAE=0.680276 validation MAE=0.703432,rank=3\n",
      "[SoftImpute] Iter 169: observed MAE=0.680204 validation MAE=0.703370,rank=3\n",
      "[SoftImpute] Iter 170: observed MAE=0.680133 validation MAE=0.703309,rank=3\n",
      "[SoftImpute] Iter 171: observed MAE=0.680063 validation MAE=0.703248,rank=3\n",
      "[SoftImpute] Iter 172: observed MAE=0.679993 validation MAE=0.703188,rank=3\n",
      "[SoftImpute] Iter 173: observed MAE=0.679924 validation MAE=0.703129,rank=3\n",
      "[SoftImpute] Iter 174: observed MAE=0.679856 validation MAE=0.703071,rank=3\n",
      "[SoftImpute] Iter 175: observed MAE=0.679788 validation MAE=0.703013,rank=3\n",
      "[SoftImpute] Iter 176: observed MAE=0.679721 validation MAE=0.702956,rank=3\n",
      "[SoftImpute] Iter 177: observed MAE=0.679655 validation MAE=0.702899,rank=3\n",
      "[SoftImpute] Iter 178: observed MAE=0.679589 validation MAE=0.702843,rank=3\n",
      "[SoftImpute] Iter 179: observed MAE=0.679524 validation MAE=0.702787,rank=3\n",
      "[SoftImpute] Iter 180: observed MAE=0.679459 validation MAE=0.702731,rank=3\n",
      "[SoftImpute] Iter 181: observed MAE=0.679396 validation MAE=0.702676,rank=3\n",
      "[SoftImpute] Iter 182: observed MAE=0.679332 validation MAE=0.702621,rank=3\n",
      "[SoftImpute] Iter 183: observed MAE=0.679270 validation MAE=0.702567,rank=3\n",
      "[SoftImpute] Iter 184: observed MAE=0.679208 validation MAE=0.702514,rank=3\n",
      "[SoftImpute] Iter 185: observed MAE=0.679147 validation MAE=0.702461,rank=3\n",
      "[SoftImpute] Iter 186: observed MAE=0.679086 validation MAE=0.702409,rank=3\n",
      "[SoftImpute] Iter 187: observed MAE=0.679025 validation MAE=0.702357,rank=3\n",
      "[SoftImpute] Iter 188: observed MAE=0.678966 validation MAE=0.702306,rank=3\n",
      "[SoftImpute] Iter 189: observed MAE=0.678907 validation MAE=0.702255,rank=3\n",
      "[SoftImpute] Iter 190: observed MAE=0.678848 validation MAE=0.702205,rank=3\n",
      "[SoftImpute] Iter 191: observed MAE=0.678790 validation MAE=0.702155,rank=3\n",
      "[SoftImpute] Iter 192: observed MAE=0.678733 validation MAE=0.702106,rank=3\n",
      "[SoftImpute] Iter 193: observed MAE=0.678676 validation MAE=0.702057,rank=3\n",
      "[SoftImpute] Iter 194: observed MAE=0.678619 validation MAE=0.702009,rank=3\n",
      "[SoftImpute] Iter 195: observed MAE=0.678563 validation MAE=0.701961,rank=3\n",
      "[SoftImpute] Iter 196: observed MAE=0.678508 validation MAE=0.701913,rank=3\n",
      "[SoftImpute] Iter 197: observed MAE=0.678453 validation MAE=0.701866,rank=3\n",
      "[SoftImpute] Iter 198: observed MAE=0.678399 validation MAE=0.701819,rank=3\n",
      "[SoftImpute] Iter 199: observed MAE=0.678345 validation MAE=0.701772,rank=3\n",
      "[SoftImpute] Iter 200: observed MAE=0.678292 validation MAE=0.701726,rank=3\n",
      "[SoftImpute] Iter 201: observed MAE=0.678239 validation MAE=0.701680,rank=3\n",
      "[SoftImpute] Iter 202: observed MAE=0.678186 validation MAE=0.701635,rank=3\n",
      "[SoftImpute] Iter 203: observed MAE=0.678135 validation MAE=0.701590,rank=3\n",
      "[SoftImpute] Iter 204: observed MAE=0.678083 validation MAE=0.701545,rank=3\n",
      "[SoftImpute] Iter 205: observed MAE=0.678032 validation MAE=0.701500,rank=3\n",
      "[SoftImpute] Iter 206: observed MAE=0.677982 validation MAE=0.701456,rank=3\n",
      "[SoftImpute] Iter 207: observed MAE=0.677932 validation MAE=0.701412,rank=3\n",
      "[SoftImpute] Iter 208: observed MAE=0.677883 validation MAE=0.701368,rank=3\n",
      "[SoftImpute] Iter 209: observed MAE=0.677834 validation MAE=0.701325,rank=3\n",
      "[SoftImpute] Iter 210: observed MAE=0.677785 validation MAE=0.701283,rank=3\n",
      "[SoftImpute] Iter 211: observed MAE=0.677737 validation MAE=0.701241,rank=3\n",
      "[SoftImpute] Iter 212: observed MAE=0.677690 validation MAE=0.701199,rank=3\n",
      "[SoftImpute] Iter 213: observed MAE=0.677643 validation MAE=0.701157,rank=3\n",
      "[SoftImpute] Iter 214: observed MAE=0.677596 validation MAE=0.701116,rank=3\n",
      "[SoftImpute] Iter 215: observed MAE=0.677550 validation MAE=0.701075,rank=3\n",
      "[SoftImpute] Iter 216: observed MAE=0.677504 validation MAE=0.701035,rank=3\n",
      "[SoftImpute] Iter 217: observed MAE=0.677458 validation MAE=0.700996,rank=3\n",
      "[SoftImpute] Iter 218: observed MAE=0.677414 validation MAE=0.700956,rank=3\n",
      "[SoftImpute] Iter 219: observed MAE=0.677369 validation MAE=0.700918,rank=3\n",
      "[SoftImpute] Iter 220: observed MAE=0.677325 validation MAE=0.700879,rank=3\n",
      "[SoftImpute] Iter 221: observed MAE=0.677281 validation MAE=0.700841,rank=3\n",
      "[SoftImpute] Iter 222: observed MAE=0.677238 validation MAE=0.700803,rank=3\n",
      "[SoftImpute] Iter 223: observed MAE=0.677195 validation MAE=0.700766,rank=3\n",
      "[SoftImpute] Iter 224: observed MAE=0.677152 validation MAE=0.700728,rank=3\n",
      "[SoftImpute] Iter 225: observed MAE=0.677110 validation MAE=0.700691,rank=3\n",
      "[SoftImpute] Iter 226: observed MAE=0.677068 validation MAE=0.700655,rank=3\n",
      "[SoftImpute] Iter 227: observed MAE=0.677027 validation MAE=0.700618,rank=3\n",
      "[SoftImpute] Iter 228: observed MAE=0.676986 validation MAE=0.700582,rank=3\n",
      "[SoftImpute] Iter 229: observed MAE=0.676946 validation MAE=0.700547,rank=3\n",
      "[SoftImpute] Iter 230: observed MAE=0.676905 validation MAE=0.700511,rank=3\n",
      "[SoftImpute] Iter 231: observed MAE=0.676865 validation MAE=0.700476,rank=3\n",
      "[SoftImpute] Iter 232: observed MAE=0.676826 validation MAE=0.700442,rank=3\n",
      "[SoftImpute] Iter 233: observed MAE=0.676786 validation MAE=0.700407,rank=3\n",
      "[SoftImpute] Iter 234: observed MAE=0.676747 validation MAE=0.700373,rank=3\n",
      "[SoftImpute] Iter 235: observed MAE=0.676709 validation MAE=0.700339,rank=3\n",
      "[SoftImpute] Iter 236: observed MAE=0.676671 validation MAE=0.700305,rank=3\n",
      "[SoftImpute] Iter 237: observed MAE=0.676633 validation MAE=0.700272,rank=3\n",
      "[SoftImpute] Iter 238: observed MAE=0.676595 validation MAE=0.700239,rank=3\n",
      "[SoftImpute] Iter 239: observed MAE=0.676558 validation MAE=0.700207,rank=3\n",
      "[SoftImpute] Iter 240: observed MAE=0.676521 validation MAE=0.700174,rank=3\n",
      "[SoftImpute] Iter 241: observed MAE=0.676485 validation MAE=0.700142,rank=3\n",
      "[SoftImpute] Iter 242: observed MAE=0.676449 validation MAE=0.700110,rank=3\n",
      "[SoftImpute] Iter 243: observed MAE=0.676413 validation MAE=0.700079,rank=3\n",
      "[SoftImpute] Iter 244: observed MAE=0.676377 validation MAE=0.700047,rank=3\n",
      "[SoftImpute] Iter 245: observed MAE=0.676342 validation MAE=0.700016,rank=3\n",
      "[SoftImpute] Iter 246: observed MAE=0.676307 validation MAE=0.699985,rank=3\n",
      "[SoftImpute] Iter 247: observed MAE=0.676272 validation MAE=0.699955,rank=3\n",
      "[SoftImpute] Iter 248: observed MAE=0.676238 validation MAE=0.699924,rank=3\n",
      "[SoftImpute] Iter 249: observed MAE=0.676204 validation MAE=0.699894,rank=3\n",
      "[SoftImpute] Iter 250: observed MAE=0.676170 validation MAE=0.699864,rank=3\n",
      "[SoftImpute] Iter 251: observed MAE=0.676137 validation MAE=0.699835,rank=3\n",
      "[SoftImpute] Iter 252: observed MAE=0.676104 validation MAE=0.699805,rank=3\n",
      "[SoftImpute] Iter 253: observed MAE=0.676071 validation MAE=0.699776,rank=3\n",
      "[SoftImpute] Iter 254: observed MAE=0.676038 validation MAE=0.699747,rank=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 255: observed MAE=0.676006 validation MAE=0.699718,rank=3\n",
      "[SoftImpute] Iter 256: observed MAE=0.675974 validation MAE=0.699690,rank=3\n",
      "[SoftImpute] Iter 257: observed MAE=0.675942 validation MAE=0.699661,rank=3\n",
      "[SoftImpute] Iter 258: observed MAE=0.675911 validation MAE=0.699633,rank=3\n",
      "[SoftImpute] Iter 259: observed MAE=0.675879 validation MAE=0.699605,rank=3\n",
      "[SoftImpute] Iter 260: observed MAE=0.675848 validation MAE=0.699578,rank=3\n",
      "[SoftImpute] Iter 261: observed MAE=0.675817 validation MAE=0.699550,rank=3\n",
      "[SoftImpute] Iter 262: observed MAE=0.675787 validation MAE=0.699523,rank=3\n",
      "[SoftImpute] Iter 263: observed MAE=0.675757 validation MAE=0.699497,rank=3\n",
      "[SoftImpute] Iter 264: observed MAE=0.675727 validation MAE=0.699470,rank=3\n",
      "[SoftImpute] Iter 265: observed MAE=0.675697 validation MAE=0.699444,rank=3\n",
      "[SoftImpute] Iter 266: observed MAE=0.675668 validation MAE=0.699418,rank=3\n",
      "[SoftImpute] Iter 267: observed MAE=0.675639 validation MAE=0.699392,rank=3\n",
      "[SoftImpute] Iter 268: observed MAE=0.675610 validation MAE=0.699366,rank=3\n",
      "[SoftImpute] Iter 269: observed MAE=0.675581 validation MAE=0.699341,rank=3\n",
      "[SoftImpute] Iter 270: observed MAE=0.675553 validation MAE=0.699316,rank=3\n",
      "[SoftImpute] Iter 271: observed MAE=0.675525 validation MAE=0.699291,rank=3\n",
      "[SoftImpute] Iter 272: observed MAE=0.675497 validation MAE=0.699266,rank=3\n",
      "[SoftImpute] Iter 273: observed MAE=0.675469 validation MAE=0.699242,rank=3\n",
      "[SoftImpute] Iter 274: observed MAE=0.675442 validation MAE=0.699217,rank=3\n",
      "[SoftImpute] Iter 275: observed MAE=0.675415 validation MAE=0.699193,rank=3\n",
      "[SoftImpute] Iter 276: observed MAE=0.675388 validation MAE=0.699169,rank=3\n",
      "[SoftImpute] Iter 277: observed MAE=0.675361 validation MAE=0.699146,rank=3\n",
      "[SoftImpute] Iter 278: observed MAE=0.675335 validation MAE=0.699122,rank=3\n",
      "[SoftImpute] Iter 279: observed MAE=0.675308 validation MAE=0.699098,rank=3\n",
      "[SoftImpute] Iter 280: observed MAE=0.675282 validation MAE=0.699075,rank=3\n",
      "[SoftImpute] Iter 281: observed MAE=0.675257 validation MAE=0.699052,rank=3\n",
      "[SoftImpute] Iter 282: observed MAE=0.675231 validation MAE=0.699029,rank=3\n",
      "[SoftImpute] Iter 283: observed MAE=0.675206 validation MAE=0.699006,rank=3\n",
      "[SoftImpute] Iter 284: observed MAE=0.675180 validation MAE=0.698983,rank=3\n",
      "[SoftImpute] Iter 285: observed MAE=0.675155 validation MAE=0.698961,rank=3\n",
      "[SoftImpute] Iter 286: observed MAE=0.675131 validation MAE=0.698939,rank=3\n",
      "[SoftImpute] Iter 287: observed MAE=0.675106 validation MAE=0.698917,rank=3\n",
      "[SoftImpute] Iter 288: observed MAE=0.675082 validation MAE=0.698895,rank=3\n",
      "[SoftImpute] Iter 289: observed MAE=0.675058 validation MAE=0.698873,rank=3\n",
      "[SoftImpute] Iter 290: observed MAE=0.675034 validation MAE=0.698851,rank=3\n",
      "[SoftImpute] Iter 291: observed MAE=0.675010 validation MAE=0.698830,rank=3\n",
      "[SoftImpute] Iter 292: observed MAE=0.674986 validation MAE=0.698808,rank=3\n",
      "[SoftImpute] Iter 293: observed MAE=0.674963 validation MAE=0.698787,rank=3\n",
      "[SoftImpute] Iter 294: observed MAE=0.674940 validation MAE=0.698766,rank=3\n",
      "[SoftImpute] Iter 295: observed MAE=0.674917 validation MAE=0.698745,rank=3\n",
      "[SoftImpute] Iter 296: observed MAE=0.674894 validation MAE=0.698724,rank=3\n",
      "[SoftImpute] Iter 297: observed MAE=0.674872 validation MAE=0.698704,rank=3\n",
      "[SoftImpute] Iter 298: observed MAE=0.674849 validation MAE=0.698683,rank=3\n",
      "[SoftImpute] Iter 299: observed MAE=0.674827 validation MAE=0.698663,rank=3\n",
      "[SoftImpute] Iter 300: observed MAE=0.674805 validation MAE=0.698643,rank=3\n",
      "[SoftImpute] Stopped after iteration 300 for lambda=4.736946\n",
      "final num of user group: 12\n",
      "final num of item group: 8\n",
      "change mode state : True\n",
      "time cost: 896.2899873256683\n",
      "After the matrix factor stage, training error is 0.67481, validation error is 0.69864\n",
      "1\n",
      "ListWrapper(['Gender', 'Age', 'Occupation', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.89092, val loss: 0.88951\n",
      "Main effects training epoch: 2, train loss: 0.87942, val loss: 0.87762\n",
      "Main effects training epoch: 3, train loss: 0.87497, val loss: 0.87289\n",
      "Main effects training epoch: 4, train loss: 0.87128, val loss: 0.86912\n",
      "Main effects training epoch: 5, train loss: 0.87047, val loss: 0.86824\n",
      "Main effects training epoch: 6, train loss: 0.86775, val loss: 0.86539\n",
      "Main effects training epoch: 7, train loss: 0.86705, val loss: 0.86462\n",
      "Main effects training epoch: 8, train loss: 0.86737, val loss: 0.86490\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gaminet.utils import local_visualize\n",
    "from gaminet.utils import global_visualize_density\n",
    "from gaminet.utils import feature_importance_visualize\n",
    "from gaminet.utils import plot_trajectory\n",
    "from gaminet.utils import plot_regularization\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from lvxnn.LVXNN import LV_XNN\n",
    "from lvxnn.DataReader import data_initialize\n",
    "\n",
    "train= pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "list1 = train.columns\n",
    "meta_info = OrderedDict()\n",
    "for i in list1:\n",
    "    meta_info[i]={'type': 'categorical','source':'item'} \n",
    "meta_info['Occupation']={\"type\":\"categorical\",'source':'user'}\n",
    "meta_info['Gender']={\"type\":\"categorical\",'source':'user'}\n",
    "meta_info['Age'] = {\"type\":\"continues\",'source':'user'}\n",
    "meta_info['user_id']={\"type\":\"id\",'source':'user'}\n",
    "meta_info['item_id']={\"type\":\"id\",'source':'item'}\n",
    "meta_info['target']={\"type\":\"target\",'source':''}\n",
    "\n",
    "\n",
    "tr_x, tr_Xi, tr_y , te_x , te_Xi, te_y, meta_info, model_info = data_initialize(train,test,meta_info,\"Regression\")\n",
    "\n",
    "\n",
    "def auto_test():\n",
    "    cold_mae = []\n",
    "    cold_rmse = []\n",
    "    warm_mae = []\n",
    "    warm_rmse = []\n",
    "    gami_mae = []\n",
    "    gami_rmse = []\n",
    "\n",
    "    for times in range(10):\n",
    "        \n",
    "        print(times)\n",
    "\n",
    "\n",
    "        model = LV_XNN(model_info=model_info, meta_info=meta_info, subnet_arch=[8, 16],interact_arch=[20, 10],activation_func=tf.tanh, batch_size=1000, lr_bp=0.01, auto_tune=False,\n",
    "               interaction_epochs=20,main_effect_epochs=20,tuning_epochs=20,loss_threshold_main=0.01,loss_threshold_inter=0.01,alpha=0.5,\n",
    "              verbose=True,val_ratio=0.125, early_stop_thres=100,interact_num=10,u_group_num=30,i_group_num=50,scale_ratio=1,n_power_iterations=5,n_oversamples=0,\n",
    "              mf_training_iters=1,mf_tuning_iters=300,change_mode=True,convergence_threshold=0.001,max_rank=3,shrinkage_value=20,random_state=times)\n",
    "    \n",
    "        st_time = time.time()\n",
    "        model.fit(tr_x,tr_Xi, tr_y)\n",
    "        ed_time = time.time()\n",
    "    \n",
    "        \n",
    "        pred = model.predict(te_x, te_Xi)\n",
    "        \n",
    "        cold_y = te_y[(te_Xi[:,1] == 'cold') | (te_Xi[:,0] == 'cold')]\n",
    "        cold_pred = pred[(te_Xi[:,1] == 'cold') | (te_Xi[:,0] == 'cold')]\n",
    "        warm_y = te_y[(te_Xi[:,1] != 'cold') & (te_Xi[:,0] != 'cold')]\n",
    "        warm_pred = pred[(te_Xi[:,1] != 'cold') & (te_Xi[:,0] != 'cold')]\n",
    "    \n",
    "        cold_mae.append(mean_absolute_error(cold_y,cold_pred))\n",
    "        cold_rmse.append(mean_squared_error(cold_y,cold_pred)**0.5)\n",
    "        warm_mae.append(mean_absolute_error(warm_y,warm_pred))\n",
    "        warm_rmse.append(mean_squared_error(warm_y,warm_pred)**0.5)\n",
    "        \n",
    "\n",
    "        gami_mae.append(mean_absolute_error(te_y,model.final_gam_model.predict(te_x)))\n",
    "        gami_rmse.append(mean_squared_error(te_y,model.final_gam_model.predict(te_x))**0.5)\n",
    "        \n",
    "    i_result = np.array([np.mean(cold_mae),np.mean(cold_rmse),np.mean(warm_mae),np.mean(warm_rmse)]).reshape(1,-1)\n",
    "    result = pd.DataFrame(i_result,columns=['cold_mae','cold_rmse','warm_mae','warm_rmse'])\n",
    "    \n",
    "    g_result = np.array([np.mean(gami_mae),np.mean(gami_rmse)]).reshape(1,-1)\n",
    "    g_result = pd.DataFrame(g_result,columns=['mae','rmse'])\n",
    "    \n",
    "    return result, g_result\n",
    "\n",
    "results, g_result = (auto_test())\n",
    "results.to_csv('result/LVXNN_result.csv',index=None)\n",
    "g_result.to_csv('result/gami_result.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "train= pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "data,val = train_test_split(train,test_size=0.125)\n",
    "\n",
    "x=data.iloc[:,:-1].values\n",
    "y=data.iloc[:,-1].values\n",
    "x_t = test.iloc[:,:-1].values\n",
    "y_t = test.iloc[:,-1].values\n",
    "\n",
    "enc = MinMaxScaler()\n",
    "x = enc.fit_transform(x)\n",
    "x_t = enc.fit_transform(x_t)\n",
    "\n",
    "def auto_test():\n",
    "    mae = []\n",
    "    rmse = []\n",
    "    for times in range(10):\n",
    "        xgb = XGBRegressor(n_jobs=-1)\n",
    "        xgb.fit(x,y)\n",
    "        pred = xgb.predict(x_t)\n",
    "        \n",
    "        mae.append(mean_absolute_error(y_t,pred))\n",
    "        rmse.append(mean_squared_error(y_t,pred)**0.5)\n",
    "\n",
    "    i_result = np.array([np.mean(mae),np.mean(rmse)]).reshape(1,-1)\n",
    "    result = pd.DataFrame(i_result,columns=['mae','rmse'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "results = (auto_test())\n",
    "results.to_csv('result/xgboost_result.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train= pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "data,val = train_test_split(train,test_size=0.125)\n",
    "\n",
    "Xi = data.iloc[:,-3:-1].values\n",
    "y = data.iloc[:,-1].values\n",
    "Xi_t = test.iloc[:,-3:-1].values\n",
    "y_t = test.iloc[:,-1].values\n",
    "\n",
    "tr_ratings_dict = {'itemID': Xi[:,1].tolist(),\n",
    "                'userID': Xi[:,0].tolist(),\n",
    "                'rating': y.tolist()}\n",
    "\n",
    "tr_df = pd.DataFrame(tr_ratings_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(y.min(), y.max()))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "tr_data = Dataset.load_from_df(tr_df[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "tr_data = tr_data.build_full_trainset()\n",
    "\n",
    "def auto_test():\n",
    "    mae = []\n",
    "    rmse = []\n",
    "    for j in range(10):\n",
    "        model = SVD(n_factors=3)\n",
    "\n",
    "        model.fit(tr_data)\n",
    "\n",
    "        pred = []\n",
    "        \n",
    "        for i in range(Xi_t.shape[0]):\n",
    "            pred.append(model.predict(Xi_t[i,0],Xi_t[i,1],Xi_t[i,0]).est)\n",
    "    \n",
    "        pred2 = np.array(pred).ravel()\n",
    "\n",
    "        mae.append(mean_absolute_error(y_t,pred2))\n",
    "        rmse.append(mean_squared_error(y_t,pred2)**0.5)\n",
    "    \n",
    "\n",
    "    i_result = np.array([np.mean(mae),np.mean(rmse)]).reshape(1,-1)\n",
    "    result = pd.DataFrame(i_result,columns=['mae','rmse'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "results = (auto_test())\n",
    "results.to_csv('result/svd_result.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deepfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0613 14:05:39.747494  9740 deprecation.py:323] From C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000261068156A8>, 'loss_type': 'mse', 'epoch': 50, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x000002611A8EB378>, 'random_seed': 0, 'feature_size': 9787, 'field_size': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 14:05:51.088824  9740 deprecation.py:506] From ../benchmark/deepfm\\DeepFM.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000261068156A8>, 'loss_type': 'mse', 'epoch': 50, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x000002611A8EB378>, 'random_seed': 1, 'feature_size': 9787, 'field_size': 23}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000261068156A8>, 'loss_type': 'mse', 'epoch': 50, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x000002611A8EB378>, 'random_seed': 2, 'feature_size': 9787, 'field_size': 23}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000261068156A8>, 'loss_type': 'mse', 'epoch': 50, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x000002611A8EB378>, 'random_seed': 3, 'feature_size': 9787, 'field_size': 23}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000261068156A8>, 'loss_type': 'mse', 'epoch': 50, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x000002611A8EB378>, 'random_seed': 4, 'feature_size': 9787, 'field_size': 23}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000261068156A8>, 'loss_type': 'mse', 'epoch': 50, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x000002611A8EB378>, 'random_seed': 0, 'feature_size': 9787, 'field_size': 23}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000261068156A8>, 'loss_type': 'mse', 'epoch': 50, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x000002611A8EB378>, 'random_seed': 1, 'feature_size': 9787, 'field_size': 23}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000261068156A8>, 'loss_type': 'mse', 'epoch': 50, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x000002611A8EB378>, 'random_seed': 2, 'feature_size': 9787, 'field_size': 23}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000261068156A8>, 'loss_type': 'mse', 'epoch': 50, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x000002611A8EB378>, 'random_seed': 3, 'feature_size': 9787, 'field_size': 23}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000261068156A8>, 'loss_type': 'mse', 'epoch': 50, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x000002611A8EB378>, 'random_seed': 4, 'feature_size': 9787, 'field_size': 23}\n"
     ]
    }
   ],
   "source": [
    "class config():\n",
    "# set the path-to-files\n",
    "\n",
    "    TRAIN_FILE = \"./data/train.csv\"\n",
    "    TEST_FILE = \"./data/test.csv\"\n",
    "    SUB_DIR = \"./output\"\n",
    "    NUM_SPLITS = 3\n",
    "    RANDOM_SEED = 2017\n",
    "\n",
    "# types of columns of the dataset dataframe\n",
    "    CATEGORICAL_COLS = ['Occupation']\n",
    "    NUMERIC_COLS = ['Gender','Age','Action', 'Adventure', 'Animation',\n",
    "       \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "       'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "       'Thriller', 'War', 'Western']\n",
    "    IGNORE_COLS = [\"target\"]\n",
    "    \n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('../benchmark/deepfm/')\n",
    "from DataReader import FeatureDictionary, DataParser\n",
    "from DeepFM import DeepFM\n",
    "\n",
    "\n",
    "def _load_data():\n",
    "\n",
    "    dfTrain = pd.read_csv(config.TRAIN_FILE)\n",
    "    dfTest = pd.read_csv(config.TEST_FILE)\n",
    "\n",
    "    def preprocess(df):        \n",
    "        cols = [c for c in df.columns if c not in [\"target\"]]\n",
    "        return df\n",
    "\n",
    "    dfTrain = preprocess(dfTrain)\n",
    "    dfTest = preprocess(dfTest)\n",
    "    cols = [c for c in dfTrain.columns if c not in [\"target\"]]\n",
    "\n",
    "\n",
    "    X_train = dfTrain[cols].values\n",
    "    y_train = dfTrain[\"target\"].values\n",
    "    X_test = dfTest[cols].values\n",
    "    \n",
    "    ids_test = dfTest[\"user_id\"].values\n",
    "    idv_test = dfTest[\"item_id\"].values\n",
    "    y_test = dfTest['target'].values\n",
    "        \n",
    "    return dfTrain, dfTest, X_train, y_train, X_test, ids_test,idv_test, y_test\n",
    "\n",
    "\n",
    "def _run_base_model_dfm(dfTrain, dfTest, folds, dfm_params):\n",
    "    fd = FeatureDictionary(dfTrain=dfTrain, dfTest=dfTest,\n",
    "                           numeric_cols=config.NUMERIC_COLS,\n",
    "                           ignore_cols=config.IGNORE_COLS)\n",
    "    data_parser = DataParser(feat_dict=fd)\n",
    "    Xi_train, Xv_train, y_train = data_parser.parse(df=dfTrain, has_label=True)\n",
    "    Xi_test, Xv_test, ids_test,idv_test = data_parser.parse(df=dfTest)\n",
    "    \n",
    "    dfm_params[\"feature_size\"] = fd.feat_dim\n",
    "    dfm_params[\"field_size\"] = len(Xi_train[0])\n",
    "    print(dfm_params)\n",
    "\n",
    "    y_train_meta = np.zeros((dfTrain.shape[0], 1), dtype=float)\n",
    "    y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)\n",
    "    _get = lambda x, l: [x[i] for i in l]\n",
    "    gini_results_cv = np.zeros(len(folds), dtype=float)\n",
    "    gini_results_epoch_train = np.zeros((len(folds), dfm_params[\"epoch\"]), dtype=float)\n",
    "    gini_results_epoch_valid = np.zeros((len(folds), dfm_params[\"epoch\"]), dtype=float)\n",
    "    for i, (train_idx, valid_idx) in enumerate(folds):\n",
    "        Xi_train_, Xv_train_, y_train_ = _get(Xi_train, train_idx), _get(Xv_train, train_idx), _get(y_train, train_idx)\n",
    "        Xi_valid_, Xv_valid_, y_valid_ = _get(Xi_train, valid_idx), _get(Xv_train, valid_idx), _get(y_train, valid_idx)\n",
    "\n",
    "        dfm = DeepFM(**dfm_params)\n",
    "        dfm.fit(Xi_train_, Xv_train_, y_train_, Xi_valid_, Xv_valid_, y_valid_)\n",
    "\n",
    "        y_train_meta[valid_idx,0] = dfm.predict(Xi_valid_, Xv_valid_)\n",
    "        y_test_meta[:,0] += dfm.predict(Xi_test, Xv_test)\n",
    "        \n",
    "        gini_results_cv[i] = mean_absolute_error(y_valid_, y_train_meta[valid_idx])\n",
    "        gini_results_epoch_train[i] = dfm.train_result\n",
    "        gini_results_epoch_valid[i] = dfm.valid_result\n",
    "\n",
    "    y_test_meta /= float(len(folds))\n",
    "\n",
    "    # save result\n",
    "    return y_train_meta, y_test_meta\n",
    "\n",
    "# load data\n",
    "dfTrain, dfTest, X_train, y_train, X_test, ids_test ,idv_test, y_test= _load_data()\n",
    "\n",
    "# folds\n",
    "folds = list(KFold(n_splits=config.NUM_SPLITS, shuffle=True,\n",
    "                             random_state=config.RANDOM_SEED).split(X_train, y_train))\n",
    "\n",
    "\n",
    "\n",
    "# ------------------ DeepFM Model ------------------\n",
    "# params\n",
    "dfm_params = {\n",
    "    \"embedding_size\": 3,\n",
    "    \"deep_layers\": [32, 32],\n",
    "    \"use_deep\" : True ,\n",
    "    \"use_fm\" : True , \n",
    "    \"deep_layers_activation\": tf.nn.relu,\n",
    "    \"loss_type\" : \"mse\",\n",
    "    \"epoch\": 50 ,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"optimizer_type\": \"adam\",\n",
    "    \"batch_norm\": 0,\n",
    "    \"batch_norm_decay\": 0.995,\n",
    "    \"l2_reg\": 0.01,\n",
    "    \"verbose\": False,\n",
    "    \"eval_metric\": mean_absolute_error,\n",
    "    \"random_seed\": config.RANDOM_SEED\n",
    "}\n",
    "\n",
    "def auto_test(deep):\n",
    "    mae = []\n",
    "    rmse = []\n",
    "    dfm_params['use_deep']=deep\n",
    "    \n",
    "    for i in range(5):\n",
    "        dfm_params['random_seed']=i\n",
    "        y_train_dfm, y_test_dfm = _run_base_model_dfm(dfTrain, dfTest, folds, dfm_params)\n",
    "        mae.append(mean_absolute_error(y_test,y_test_dfm))\n",
    "        rmse.append(mean_squared_error(y_test,y_test_dfm)**0.5)\n",
    "    \n",
    "    i_result = np.array([np.mean(mae),np.mean(rmse)]).reshape(1,-1)\n",
    "    results = pd.DataFrame(i_result,columns=['mae','rmse'])\n",
    "    \n",
    "    return results\n",
    "result_1 = (auto_test(True))\n",
    "result_2 = (auto_test(False))\n",
    "result_1.to_csv('result/deepfm_result.csv',index=None)\n",
    "result_2.to_csv('result/fm_result.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
