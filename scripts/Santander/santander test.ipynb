{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LVXNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 108.45 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\lvxnn\\DataReader.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.int8)\n",
      "../..\\lvxnn\\DataReader.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.int16)\n",
      "../..\\lvxnn\\DataReader.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "../..\\lvxnn\\DataReader.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 22.80 MB\n",
      "Decreased by 79.0%\n",
      "Memory usage of dataframe is 27.11 MB\n",
      "Memory usage after optimization is: 5.70 MB\n",
      "Decreased by 79.0%\n",
      "cold start user: 13104\n",
      "cold start item: 9\n",
      "0\n",
      "ListWrapper(['ind_empleado', 'sex', 'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente', 'segmento', 'pais_residencia', 'canal_entrada', 'age', 'cust_seniority', 'income', 'marriage', 'item'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.16054, val loss: 0.16017\n",
      "Main effects training epoch: 2, train loss: 0.16036, val loss: 0.16004\n",
      "Main effects training epoch: 3, train loss: 0.16008, val loss: 0.15986\n",
      "Main effects training epoch: 4, train loss: 0.15988, val loss: 0.15960\n",
      "Main effects training epoch: 5, train loss: 0.15967, val loss: 0.15946\n",
      "Main effects training epoch: 6, train loss: 0.15980, val loss: 0.15968\n",
      "Main effects training epoch: 7, train loss: 0.15977, val loss: 0.15954\n",
      "Main effects training epoch: 8, train loss: 0.15977, val loss: 0.15962\n",
      "Main effects training epoch: 9, train loss: 0.15962, val loss: 0.15944\n",
      "Main effects training epoch: 10, train loss: 0.15963, val loss: 0.15946\n",
      "Main effects training epoch: 11, train loss: 0.15964, val loss: 0.15952\n",
      "Main effects training epoch: 12, train loss: 0.15958, val loss: 0.15938\n",
      "Main effects training epoch: 13, train loss: 0.15978, val loss: 0.15967\n",
      "Main effects training epoch: 14, train loss: 0.15958, val loss: 0.15944\n",
      "Main effects training epoch: 15, train loss: 0.16001, val loss: 0.15983\n",
      "Main effects training epoch: 16, train loss: 0.15962, val loss: 0.15946\n",
      "Main effects training epoch: 17, train loss: 0.16111, val loss: 0.16100\n",
      "Main effects training epoch: 18, train loss: 0.16001, val loss: 0.15991\n",
      "Main effects training epoch: 19, train loss: 0.15991, val loss: 0.15976\n",
      "Main effects training epoch: 20, train loss: 0.15963, val loss: 0.15949\n",
      "##########Stage 1: main effect training stop.##########\n",
      "14 main effects are pruned, start tuning.##########\n",
      "Main effects tuning epoch: 1, train loss: 0.15978, val loss: 0.15959\n",
      "Main effects tuning epoch: 2, train loss: 0.15989, val loss: 0.15975\n",
      "Main effects tuning epoch: 3, train loss: 0.16002, val loss: 0.15985\n",
      "Main effects tuning epoch: 4, train loss: 0.15988, val loss: 0.15970\n",
      "Main effects tuning epoch: 5, train loss: 0.15973, val loss: 0.15959\n",
      "Main effects tuning epoch: 6, train loss: 0.16038, val loss: 0.16023\n",
      "Main effects tuning epoch: 7, train loss: 0.15971, val loss: 0.15957\n",
      "Main effects tuning epoch: 8, train loss: 0.16024, val loss: 0.16010\n",
      "Main effects tuning epoch: 9, train loss: 0.15968, val loss: 0.15949\n",
      "Main effects tuning epoch: 10, train loss: 0.15969, val loss: 0.15957\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.14627, val loss: 0.14730\n",
      "Interaction training epoch: 2, train loss: 0.14523, val loss: 0.14631\n",
      "Interaction training epoch: 3, train loss: 0.14483, val loss: 0.14614\n",
      "Interaction training epoch: 4, train loss: 0.14466, val loss: 0.14600\n",
      "Interaction training epoch: 5, train loss: 0.14459, val loss: 0.14576\n",
      "Interaction training epoch: 6, train loss: 0.14430, val loss: 0.14562\n",
      "Interaction training epoch: 7, train loss: 0.14496, val loss: 0.14620\n",
      "Interaction training epoch: 8, train loss: 0.14385, val loss: 0.14531\n",
      "Interaction training epoch: 9, train loss: 0.14401, val loss: 0.14544\n",
      "Interaction training epoch: 10, train loss: 0.14413, val loss: 0.14582\n",
      "Interaction training epoch: 11, train loss: 0.14373, val loss: 0.14537\n",
      "Interaction training epoch: 12, train loss: 0.14393, val loss: 0.14560\n",
      "Interaction training epoch: 13, train loss: 0.14371, val loss: 0.14533\n",
      "Interaction training epoch: 14, train loss: 0.14375, val loss: 0.14540\n",
      "Interaction training epoch: 15, train loss: 0.14519, val loss: 0.14693\n",
      "Interaction training epoch: 16, train loss: 0.14380, val loss: 0.14528\n",
      "Interaction training epoch: 17, train loss: 0.14339, val loss: 0.14506\n",
      "Interaction training epoch: 18, train loss: 0.14327, val loss: 0.14483\n",
      "Interaction training epoch: 19, train loss: 0.14325, val loss: 0.14501\n",
      "Interaction training epoch: 20, train loss: 0.14304, val loss: 0.14483\n",
      "##########Stage 2: interaction training stop.##########\n",
      "##########2 interactions are pruned, start tuning.##########\n",
      "Interaction tuning epoch: 1, train loss: 0.14334, val loss: 0.14515\n",
      "Interaction tuning epoch: 2, train loss: 0.14311, val loss: 0.14508\n",
      "Interaction tuning epoch: 3, train loss: 0.14329, val loss: 0.14515\n",
      "Interaction tuning epoch: 4, train loss: 0.14350, val loss: 0.14539\n",
      "Interaction tuning epoch: 5, train loss: 0.14305, val loss: 0.14481\n",
      "Interaction tuning epoch: 6, train loss: 0.14320, val loss: 0.14512\n",
      "Interaction tuning epoch: 7, train loss: 0.14292, val loss: 0.14488\n",
      "Interaction tuning epoch: 8, train loss: 0.14262, val loss: 0.14470\n",
      "Interaction tuning epoch: 9, train loss: 0.14291, val loss: 0.14463\n",
      "Interaction tuning epoch: 10, train loss: 0.14267, val loss: 0.14482\n",
      "####################GAMI-Net training finished.####################\n",
      "time cost: 381.6546950340271\n",
      "After the gam stage, training error is 0.14266 , validation error is 0.14482\n",
      "missing value counts: 242286\n",
      "[SoftImpute] Max Singular Value of X_init = 79.477761\n",
      "#####mf_training#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 1: observed BCE=0.059762 validation BCE=0.128003,rank=3\n",
      "[SoftImpute] Iter 2: observed BCE=0.058335 validation BCE=0.129750,rank=3\n",
      "[SoftImpute] Iter 3: observed BCE=0.057240 validation BCE=0.132436,rank=3\n",
      "[SoftImpute] Iter 4: observed BCE=0.056207 validation BCE=0.134527,rank=3\n",
      "[SoftImpute] Stopped after iteration 4 for lambda=1.589555\n",
      "final num of user group: 5\n",
      "final num of item group: 6\n",
      "change mode state : True\n",
      "time cost: 5.309386968612671\n",
      "After the matrix factor stage, training error is 0.05621, validation error is 0.13453\n",
      "1\n",
      "ListWrapper(['ind_empleado', 'sex', 'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente', 'segmento', 'pais_residencia', 'canal_entrada', 'age', 'cust_seniority', 'income', 'marriage', 'item'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.16051, val loss: 0.16018\n",
      "Main effects training epoch: 2, train loss: 0.16008, val loss: 0.15983\n",
      "Main effects training epoch: 3, train loss: 0.15984, val loss: 0.15958\n",
      "Main effects training epoch: 4, train loss: 0.15979, val loss: 0.15960\n",
      "Main effects training epoch: 5, train loss: 0.16120, val loss: 0.16116\n",
      "Main effects training epoch: 6, train loss: 0.15977, val loss: 0.15958\n",
      "Main effects training epoch: 7, train loss: 0.16014, val loss: 0.16001\n",
      "Main effects training epoch: 8, train loss: 0.15991, val loss: 0.15985\n",
      "Main effects training epoch: 9, train loss: 0.15982, val loss: 0.15967\n",
      "Main effects training epoch: 10, train loss: 0.16026, val loss: 0.16002\n",
      "Main effects training epoch: 11, train loss: 0.15962, val loss: 0.15951\n",
      "Main effects training epoch: 12, train loss: 0.16076, val loss: 0.16064\n",
      "Main effects training epoch: 13, train loss: 0.15964, val loss: 0.15943\n",
      "Main effects training epoch: 14, train loss: 0.15978, val loss: 0.15967\n",
      "Main effects training epoch: 15, train loss: 0.15975, val loss: 0.15966\n",
      "Main effects training epoch: 16, train loss: 0.15966, val loss: 0.15946\n",
      "Main effects training epoch: 17, train loss: 0.16010, val loss: 0.15983\n",
      "Main effects training epoch: 18, train loss: 0.15983, val loss: 0.15962\n",
      "Main effects training epoch: 19, train loss: 0.15975, val loss: 0.15956\n",
      "Main effects training epoch: 20, train loss: 0.15963, val loss: 0.15940\n",
      "##########Stage 1: main effect training stop.##########\n",
      "11 main effects are pruned, start tuning.##########\n",
      "Main effects tuning epoch: 1, train loss: 0.15969, val loss: 0.15945\n",
      "Main effects tuning epoch: 2, train loss: 0.15976, val loss: 0.15971\n",
      "Main effects tuning epoch: 3, train loss: 0.15965, val loss: 0.15947\n",
      "Main effects tuning epoch: 4, train loss: 0.16008, val loss: 0.15983\n",
      "Main effects tuning epoch: 5, train loss: 0.16013, val loss: 0.16016\n",
      "Main effects tuning epoch: 6, train loss: 0.15958, val loss: 0.15945\n",
      "Main effects tuning epoch: 7, train loss: 0.15965, val loss: 0.15956\n",
      "Main effects tuning epoch: 8, train loss: 0.15970, val loss: 0.15947\n",
      "Main effects tuning epoch: 9, train loss: 0.15961, val loss: 0.15961\n",
      "Main effects tuning epoch: 10, train loss: 0.15967, val loss: 0.15961\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.14633, val loss: 0.14630\n",
      "Interaction training epoch: 2, train loss: 0.14643, val loss: 0.14662\n",
      "Interaction training epoch: 3, train loss: 0.14512, val loss: 0.14548\n",
      "Interaction training epoch: 4, train loss: 0.14475, val loss: 0.14514\n",
      "Interaction training epoch: 5, train loss: 0.14466, val loss: 0.14492\n",
      "Interaction training epoch: 6, train loss: 0.14451, val loss: 0.14500\n",
      "Interaction training epoch: 7, train loss: 0.14438, val loss: 0.14489\n",
      "Interaction training epoch: 8, train loss: 0.14475, val loss: 0.14553\n",
      "Interaction training epoch: 9, train loss: 0.14428, val loss: 0.14514\n",
      "Interaction training epoch: 10, train loss: 0.14414, val loss: 0.14473\n",
      "Interaction training epoch: 11, train loss: 0.14467, val loss: 0.14534\n",
      "Interaction training epoch: 12, train loss: 0.14409, val loss: 0.14481\n",
      "Interaction training epoch: 13, train loss: 0.14405, val loss: 0.14484\n",
      "Interaction training epoch: 14, train loss: 0.14390, val loss: 0.14513\n",
      "Interaction training epoch: 15, train loss: 0.14382, val loss: 0.14472\n",
      "Interaction training epoch: 16, train loss: 0.14389, val loss: 0.14474\n",
      "Interaction training epoch: 17, train loss: 0.14422, val loss: 0.14523\n",
      "Interaction training epoch: 18, train loss: 0.14353, val loss: 0.14447\n",
      "Interaction training epoch: 19, train loss: 0.14359, val loss: 0.14471\n",
      "Interaction training epoch: 20, train loss: 0.14426, val loss: 0.14530\n",
      "##########Stage 2: interaction training stop.##########\n",
      "##########3 interactions are pruned, start tuning.##########\n",
      "Interaction tuning epoch: 1, train loss: 0.14410, val loss: 0.14547\n",
      "Interaction tuning epoch: 2, train loss: 0.14471, val loss: 0.14576\n",
      "Interaction tuning epoch: 3, train loss: 0.14426, val loss: 0.14563\n",
      "Interaction tuning epoch: 4, train loss: 0.14401, val loss: 0.14542\n",
      "Interaction tuning epoch: 5, train loss: 0.14401, val loss: 0.14548\n",
      "Interaction tuning epoch: 6, train loss: 0.14389, val loss: 0.14522\n",
      "Interaction tuning epoch: 7, train loss: 0.14397, val loss: 0.14513\n",
      "Interaction tuning epoch: 8, train loss: 0.14426, val loss: 0.14577\n",
      "Interaction tuning epoch: 9, train loss: 0.14442, val loss: 0.14608\n",
      "Interaction tuning epoch: 10, train loss: 0.14410, val loss: 0.14551\n",
      "####################GAMI-Net training finished.####################\n",
      "time cost: 385.0598855018616\n",
      "After the gam stage, training error is 0.14410 , validation error is 0.14551\n",
      "missing value counts: 242286\n",
      "[SoftImpute] Max Singular Value of X_init = 79.297611\n",
      "#####mf_training#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 1: observed BCE=0.061507 validation BCE=0.129301,rank=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 2: observed BCE=0.068228 validation BCE=0.132800,rank=3\n",
      "[SoftImpute] Iter 3: observed BCE=0.068300 validation BCE=0.133866,rank=3\n",
      "[SoftImpute] Iter 4: observed BCE=0.068069 validation BCE=0.134876,rank=3\n",
      "[SoftImpute] Stopped after iteration 4 for lambda=1.585952\n",
      "final num of user group: 6\n",
      "final num of item group: 7\n",
      "change mode state : True\n",
      "time cost: 5.703460931777954\n",
      "After the matrix factor stage, training error is 0.06807, validation error is 0.13488\n",
      "2\n",
      "ListWrapper(['ind_empleado', 'sex', 'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente', 'segmento', 'pais_residencia', 'canal_entrada', 'age', 'cust_seniority', 'income', 'marriage', 'item'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.16024, val loss: 0.16134\n",
      "Main effects training epoch: 2, train loss: 0.15980, val loss: 0.16071\n",
      "Main effects training epoch: 3, train loss: 0.16000, val loss: 0.16098\n",
      "Main effects training epoch: 4, train loss: 0.16002, val loss: 0.16095\n",
      "Main effects training epoch: 5, train loss: 0.15959, val loss: 0.16053\n",
      "Main effects training epoch: 6, train loss: 0.15969, val loss: 0.16066\n",
      "Main effects training epoch: 7, train loss: 0.15951, val loss: 0.16042\n",
      "Main effects training epoch: 8, train loss: 0.15981, val loss: 0.16074\n",
      "Main effects training epoch: 9, train loss: 0.15969, val loss: 0.16054\n",
      "Main effects training epoch: 10, train loss: 0.15957, val loss: 0.16035\n",
      "Main effects training epoch: 11, train loss: 0.16008, val loss: 0.16094\n",
      "Main effects training epoch: 12, train loss: 0.15993, val loss: 0.16085\n",
      "Main effects training epoch: 13, train loss: 0.15946, val loss: 0.16032\n",
      "Main effects training epoch: 14, train loss: 0.15963, val loss: 0.16054\n",
      "Main effects training epoch: 15, train loss: 0.15940, val loss: 0.16033\n",
      "Main effects training epoch: 16, train loss: 0.15953, val loss: 0.16040\n",
      "Main effects training epoch: 17, train loss: 0.15942, val loss: 0.16031\n",
      "Main effects training epoch: 18, train loss: 0.15954, val loss: 0.16052\n",
      "Main effects training epoch: 19, train loss: 0.15967, val loss: 0.16059\n",
      "Main effects training epoch: 20, train loss: 0.15955, val loss: 0.16045\n",
      "##########Stage 1: main effect training stop.##########\n",
      "14 main effects are pruned, start tuning.##########\n",
      "Main effects tuning epoch: 1, train loss: 0.15978, val loss: 0.16069\n",
      "Main effects tuning epoch: 2, train loss: 0.16007, val loss: 0.16087\n",
      "Main effects tuning epoch: 3, train loss: 0.15975, val loss: 0.16056\n",
      "Main effects tuning epoch: 4, train loss: 0.15982, val loss: 0.16066\n",
      "Main effects tuning epoch: 5, train loss: 0.15996, val loss: 0.16073\n",
      "Main effects tuning epoch: 6, train loss: 0.15958, val loss: 0.16040\n",
      "Main effects tuning epoch: 7, train loss: 0.15973, val loss: 0.16058\n",
      "Main effects tuning epoch: 8, train loss: 0.15967, val loss: 0.16053\n",
      "Main effects tuning epoch: 9, train loss: 0.15967, val loss: 0.16054\n",
      "Main effects tuning epoch: 10, train loss: 0.15953, val loss: 0.16042\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.14591, val loss: 0.14712\n",
      "Interaction training epoch: 2, train loss: 0.14498, val loss: 0.14611\n",
      "Interaction training epoch: 3, train loss: 0.14509, val loss: 0.14643\n",
      "Interaction training epoch: 4, train loss: 0.14464, val loss: 0.14583\n",
      "Interaction training epoch: 5, train loss: 0.14449, val loss: 0.14584\n",
      "Interaction training epoch: 6, train loss: 0.14444, val loss: 0.14600\n",
      "Interaction training epoch: 7, train loss: 0.14402, val loss: 0.14545\n",
      "Interaction training epoch: 8, train loss: 0.14395, val loss: 0.14526\n",
      "Interaction training epoch: 9, train loss: 0.14402, val loss: 0.14553\n",
      "Interaction training epoch: 10, train loss: 0.14402, val loss: 0.14555\n",
      "Interaction training epoch: 11, train loss: 0.14381, val loss: 0.14533\n",
      "Interaction training epoch: 12, train loss: 0.14405, val loss: 0.14542\n",
      "Interaction training epoch: 13, train loss: 0.14374, val loss: 0.14530\n",
      "Interaction training epoch: 14, train loss: 0.14361, val loss: 0.14504\n",
      "Interaction training epoch: 15, train loss: 0.14373, val loss: 0.14504\n",
      "Interaction training epoch: 16, train loss: 0.14376, val loss: 0.14538\n",
      "Interaction training epoch: 17, train loss: 0.14378, val loss: 0.14535\n",
      "Interaction training epoch: 18, train loss: 0.14330, val loss: 0.14495\n",
      "Interaction training epoch: 19, train loss: 0.14368, val loss: 0.14518\n",
      "Interaction training epoch: 20, train loss: 0.14327, val loss: 0.14481\n",
      "##########Stage 2: interaction training stop.##########\n",
      "##########4 interactions are pruned, start tuning.##########\n",
      "Interaction tuning epoch: 1, train loss: 0.14423, val loss: 0.14574\n",
      "Interaction tuning epoch: 2, train loss: 0.14397, val loss: 0.14523\n",
      "Interaction tuning epoch: 3, train loss: 0.14368, val loss: 0.14485\n",
      "Interaction tuning epoch: 4, train loss: 0.14399, val loss: 0.14557\n",
      "Interaction tuning epoch: 5, train loss: 0.14401, val loss: 0.14561\n",
      "Interaction tuning epoch: 6, train loss: 0.14476, val loss: 0.14623\n",
      "Interaction tuning epoch: 7, train loss: 0.14367, val loss: 0.14506\n",
      "Interaction tuning epoch: 8, train loss: 0.14348, val loss: 0.14509\n",
      "Interaction tuning epoch: 9, train loss: 0.14358, val loss: 0.14491\n",
      "Interaction tuning epoch: 10, train loss: 0.14388, val loss: 0.14542\n",
      "####################GAMI-Net training finished.####################\n",
      "time cost: 407.66210436820984\n",
      "After the gam stage, training error is 0.14388 , validation error is 0.14542\n",
      "missing value counts: 242286\n",
      "[SoftImpute] Max Singular Value of X_init = 79.062774\n",
      "#####mf_training#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 1: observed BCE=0.063338 validation BCE=0.131184,rank=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 2: observed BCE=0.064276 validation BCE=0.133477,rank=3\n",
      "[SoftImpute] Iter 3: observed BCE=0.063855 validation BCE=0.136637,rank=3\n",
      "[SoftImpute] Iter 4: observed BCE=0.063343 validation BCE=0.139808,rank=3\n",
      "[SoftImpute] Stopped after iteration 4 for lambda=1.581255\n",
      "final num of user group: 6\n",
      "final num of item group: 9\n",
      "change mode state : True\n",
      "time cost: 5.850892543792725\n",
      "After the matrix factor stage, training error is 0.06334, validation error is 0.13981\n",
      "3\n",
      "ListWrapper(['ind_empleado', 'sex', 'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente', 'segmento', 'pais_residencia', 'canal_entrada', 'age', 'cust_seniority', 'income', 'marriage', 'item'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.16110, val loss: 0.16045\n",
      "Main effects training epoch: 2, train loss: 0.16006, val loss: 0.15940\n",
      "Main effects training epoch: 3, train loss: 0.15989, val loss: 0.15928\n",
      "Main effects training epoch: 4, train loss: 0.15995, val loss: 0.15934\n",
      "Main effects training epoch: 5, train loss: 0.16033, val loss: 0.15969\n",
      "Main effects training epoch: 6, train loss: 0.15997, val loss: 0.15941\n",
      "Main effects training epoch: 7, train loss: 0.15996, val loss: 0.15928\n",
      "Main effects training epoch: 8, train loss: 0.15984, val loss: 0.15916\n",
      "Main effects training epoch: 9, train loss: 0.15978, val loss: 0.15925\n",
      "Main effects training epoch: 10, train loss: 0.15975, val loss: 0.15912\n",
      "Main effects training epoch: 11, train loss: 0.15978, val loss: 0.15915\n",
      "Main effects training epoch: 12, train loss: 0.15998, val loss: 0.15923\n",
      "Main effects training epoch: 13, train loss: 0.15986, val loss: 0.15925\n",
      "Main effects training epoch: 14, train loss: 0.15984, val loss: 0.15930\n",
      "Main effects training epoch: 15, train loss: 0.15973, val loss: 0.15917\n",
      "Main effects training epoch: 16, train loss: 0.15981, val loss: 0.15918\n",
      "Main effects training epoch: 17, train loss: 0.15962, val loss: 0.15902\n",
      "Main effects training epoch: 18, train loss: 0.15966, val loss: 0.15902\n",
      "Main effects training epoch: 19, train loss: 0.15977, val loss: 0.15904\n",
      "Main effects training epoch: 20, train loss: 0.15971, val loss: 0.15903\n",
      "##########Stage 1: main effect training stop.##########\n",
      "13 main effects are pruned, start tuning.##########\n",
      "Main effects tuning epoch: 1, train loss: 0.16004, val loss: 0.15928\n",
      "Main effects tuning epoch: 2, train loss: 0.15984, val loss: 0.15902\n",
      "Main effects tuning epoch: 3, train loss: 0.15975, val loss: 0.15898\n",
      "Main effects tuning epoch: 4, train loss: 0.15983, val loss: 0.15906\n",
      "Main effects tuning epoch: 5, train loss: 0.15977, val loss: 0.15901\n",
      "Main effects tuning epoch: 6, train loss: 0.15979, val loss: 0.15903\n",
      "Main effects tuning epoch: 7, train loss: 0.15979, val loss: 0.15909\n",
      "Main effects tuning epoch: 8, train loss: 0.15977, val loss: 0.15903\n",
      "Main effects tuning epoch: 9, train loss: 0.15987, val loss: 0.15915\n",
      "Main effects tuning epoch: 10, train loss: 0.15976, val loss: 0.15905\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.14618, val loss: 0.14591\n",
      "Interaction training epoch: 2, train loss: 0.14590, val loss: 0.14591\n",
      "Interaction training epoch: 3, train loss: 0.14499, val loss: 0.14512\n",
      "Interaction training epoch: 4, train loss: 0.14471, val loss: 0.14491\n",
      "Interaction training epoch: 5, train loss: 0.14436, val loss: 0.14444\n",
      "Interaction training epoch: 6, train loss: 0.14418, val loss: 0.14456\n",
      "Interaction training epoch: 7, train loss: 0.14412, val loss: 0.14434\n",
      "Interaction training epoch: 8, train loss: 0.14418, val loss: 0.14439\n",
      "Interaction training epoch: 9, train loss: 0.14405, val loss: 0.14426\n",
      "Interaction training epoch: 10, train loss: 0.14410, val loss: 0.14433\n",
      "Interaction training epoch: 11, train loss: 0.14397, val loss: 0.14422\n",
      "Interaction training epoch: 12, train loss: 0.14442, val loss: 0.14432\n",
      "Interaction training epoch: 13, train loss: 0.14395, val loss: 0.14431\n",
      "Interaction training epoch: 14, train loss: 0.14397, val loss: 0.14417\n",
      "Interaction training epoch: 15, train loss: 0.14435, val loss: 0.14491\n",
      "Interaction training epoch: 16, train loss: 0.14382, val loss: 0.14421\n",
      "Interaction training epoch: 17, train loss: 0.14382, val loss: 0.14442\n",
      "Interaction training epoch: 18, train loss: 0.14371, val loss: 0.14417\n",
      "Interaction training epoch: 19, train loss: 0.14371, val loss: 0.14418\n",
      "Interaction training epoch: 20, train loss: 0.14386, val loss: 0.14430\n",
      "##########Stage 2: interaction training stop.##########\n",
      "##########4 interactions are pruned, start tuning.##########\n",
      "Interaction tuning epoch: 1, train loss: 0.14465, val loss: 0.14468\n",
      "Interaction tuning epoch: 2, train loss: 0.14435, val loss: 0.14431\n",
      "Interaction tuning epoch: 3, train loss: 0.14439, val loss: 0.14426\n",
      "Interaction tuning epoch: 4, train loss: 0.14434, val loss: 0.14460\n",
      "Interaction tuning epoch: 5, train loss: 0.14492, val loss: 0.14497\n",
      "Interaction tuning epoch: 6, train loss: 0.14435, val loss: 0.14436\n",
      "Interaction tuning epoch: 7, train loss: 0.14448, val loss: 0.14457\n",
      "Interaction tuning epoch: 8, train loss: 0.14451, val loss: 0.14486\n",
      "Interaction tuning epoch: 9, train loss: 0.14466, val loss: 0.14472\n",
      "Interaction tuning epoch: 10, train loss: 0.14418, val loss: 0.14438\n",
      "####################GAMI-Net training finished.####################\n",
      "time cost: 376.7096655368805\n",
      "After the gam stage, training error is 0.14418 , validation error is 0.14438\n",
      "missing value counts: 242286\n",
      "[SoftImpute] Max Singular Value of X_init = 79.367517\n",
      "#####mf_training#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 1: observed BCE=0.061635 validation BCE=0.127252,rank=3\n",
      "[SoftImpute] Iter 2: observed BCE=0.063066 validation BCE=0.128475,rank=3\n",
      "[SoftImpute] Iter 3: observed BCE=0.065258 validation BCE=0.129449,rank=3\n",
      "[SoftImpute] Iter 4: observed BCE=0.065044 validation BCE=0.129865,rank=3\n",
      "[SoftImpute] Stopped after iteration 4 for lambda=1.587350\n",
      "final num of user group: 4\n",
      "final num of item group: 6\n",
      "change mode state : True\n",
      "time cost: 6.452313661575317\n",
      "After the matrix factor stage, training error is 0.06504, validation error is 0.12986\n",
      "4\n",
      "ListWrapper(['ind_empleado', 'sex', 'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente', 'segmento', 'pais_residencia', 'canal_entrada', 'age', 'cust_seniority', 'income', 'marriage', 'item'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.16047, val loss: 0.16092\n",
      "Main effects training epoch: 2, train loss: 0.15991, val loss: 0.16053\n",
      "Main effects training epoch: 3, train loss: 0.15998, val loss: 0.16055\n",
      "Main effects training epoch: 4, train loss: 0.15968, val loss: 0.16024\n",
      "Main effects training epoch: 5, train loss: 0.15986, val loss: 0.16043\n",
      "Main effects training epoch: 6, train loss: 0.15977, val loss: 0.16028\n",
      "Main effects training epoch: 7, train loss: 0.15960, val loss: 0.16022\n",
      "Main effects training epoch: 8, train loss: 0.15962, val loss: 0.16012\n",
      "Main effects training epoch: 9, train loss: 0.16002, val loss: 0.16057\n",
      "Main effects training epoch: 10, train loss: 0.15976, val loss: 0.16027\n",
      "Main effects training epoch: 11, train loss: 0.15962, val loss: 0.16015\n",
      "Main effects training epoch: 12, train loss: 0.15975, val loss: 0.16028\n",
      "Main effects training epoch: 13, train loss: 0.15973, val loss: 0.16026\n",
      "Main effects training epoch: 14, train loss: 0.15977, val loss: 0.16032\n",
      "Main effects training epoch: 15, train loss: 0.15956, val loss: 0.16013\n",
      "Main effects training epoch: 16, train loss: 0.15957, val loss: 0.16009\n",
      "Main effects training epoch: 17, train loss: 0.15960, val loss: 0.16006\n",
      "Main effects training epoch: 18, train loss: 0.15959, val loss: 0.16007\n",
      "Main effects training epoch: 19, train loss: 0.16027, val loss: 0.16079\n",
      "Main effects training epoch: 20, train loss: 0.15945, val loss: 0.15997\n",
      "##########Stage 1: main effect training stop.##########\n",
      "11 main effects are pruned, start tuning.##########\n",
      "Main effects tuning epoch: 1, train loss: 0.16025, val loss: 0.16083\n",
      "Main effects tuning epoch: 2, train loss: 0.16085, val loss: 0.16131\n",
      "Main effects tuning epoch: 3, train loss: 0.15958, val loss: 0.16010\n",
      "Main effects tuning epoch: 4, train loss: 0.15957, val loss: 0.16009\n",
      "Main effects tuning epoch: 5, train loss: 0.15976, val loss: 0.16044\n",
      "Main effects tuning epoch: 6, train loss: 0.15980, val loss: 0.16038\n",
      "Main effects tuning epoch: 7, train loss: 0.15955, val loss: 0.16018\n",
      "Main effects tuning epoch: 8, train loss: 0.15954, val loss: 0.16004\n",
      "Main effects tuning epoch: 9, train loss: 0.15953, val loss: 0.16006\n",
      "Main effects tuning epoch: 10, train loss: 0.15960, val loss: 0.16013\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.14705, val loss: 0.14776\n",
      "Interaction training epoch: 2, train loss: 0.14613, val loss: 0.14686\n",
      "Interaction training epoch: 3, train loss: 0.14571, val loss: 0.14634\n",
      "Interaction training epoch: 4, train loss: 0.14547, val loss: 0.14617\n",
      "Interaction training epoch: 5, train loss: 0.14493, val loss: 0.14582\n",
      "Interaction training epoch: 6, train loss: 0.14485, val loss: 0.14588\n",
      "Interaction training epoch: 7, train loss: 0.14502, val loss: 0.14575\n",
      "Interaction training epoch: 8, train loss: 0.14477, val loss: 0.14570\n",
      "Interaction training epoch: 9, train loss: 0.14467, val loss: 0.14571\n",
      "Interaction training epoch: 10, train loss: 0.14482, val loss: 0.14567\n",
      "Interaction training epoch: 11, train loss: 0.14431, val loss: 0.14532\n",
      "Interaction training epoch: 12, train loss: 0.14452, val loss: 0.14541\n",
      "Interaction training epoch: 13, train loss: 0.14393, val loss: 0.14512\n",
      "Interaction training epoch: 14, train loss: 0.14389, val loss: 0.14532\n",
      "Interaction training epoch: 15, train loss: 0.14367, val loss: 0.14497\n",
      "Interaction training epoch: 16, train loss: 0.14357, val loss: 0.14489\n",
      "Interaction training epoch: 17, train loss: 0.14358, val loss: 0.14519\n",
      "Interaction training epoch: 18, train loss: 0.14351, val loss: 0.14493\n",
      "Interaction training epoch: 19, train loss: 0.14329, val loss: 0.14465\n",
      "Interaction training epoch: 20, train loss: 0.14354, val loss: 0.14517\n",
      "##########Stage 2: interaction training stop.##########\n",
      "##########3 interactions are pruned, start tuning.##########\n",
      "Interaction tuning epoch: 1, train loss: 0.14334, val loss: 0.14484\n",
      "Interaction tuning epoch: 2, train loss: 0.14321, val loss: 0.14453\n",
      "Interaction tuning epoch: 3, train loss: 0.14370, val loss: 0.14557\n",
      "Interaction tuning epoch: 4, train loss: 0.14278, val loss: 0.14455\n",
      "Interaction tuning epoch: 5, train loss: 0.14326, val loss: 0.14481\n",
      "Interaction tuning epoch: 6, train loss: 0.14297, val loss: 0.14427\n",
      "Interaction tuning epoch: 7, train loss: 0.14295, val loss: 0.14454\n",
      "Interaction tuning epoch: 8, train loss: 0.14315, val loss: 0.14479\n",
      "Interaction tuning epoch: 9, train loss: 0.14301, val loss: 0.14429\n",
      "Interaction tuning epoch: 10, train loss: 0.14284, val loss: 0.14440\n",
      "####################GAMI-Net training finished.####################\n",
      "time cost: 424.8710880279541\n",
      "After the gam stage, training error is 0.14284 , validation error is 0.14440\n",
      "missing value counts: 242286\n",
      "[SoftImpute] Max Singular Value of X_init = 79.267508\n",
      "#####mf_training#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 1: observed BCE=0.061540 validation BCE=0.131201,rank=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 2: observed BCE=0.062628 validation BCE=0.132994,rank=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 3: observed BCE=0.062997 validation BCE=0.133706,rank=3\n",
      "[SoftImpute] Iter 4: observed BCE=0.062614 validation BCE=0.135986,rank=3\n",
      "[SoftImpute] Stopped after iteration 4 for lambda=1.585350\n",
      "final num of user group: 8\n",
      "final num of item group: 6\n",
      "change mode state : True\n",
      "time cost: 6.400266885757446\n",
      "After the matrix factor stage, training error is 0.06261, validation error is 0.13599\n",
      "5\n",
      "ListWrapper(['ind_empleado', 'sex', 'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente', 'segmento', 'pais_residencia', 'canal_entrada', 'age', 'cust_seniority', 'income', 'marriage', 'item'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.16072, val loss: 0.15918\n",
      "Main effects training epoch: 2, train loss: 0.16019, val loss: 0.15882\n",
      "Main effects training epoch: 3, train loss: 0.16030, val loss: 0.15885\n",
      "Main effects training epoch: 4, train loss: 0.16013, val loss: 0.15877\n",
      "Main effects training epoch: 5, train loss: 0.16021, val loss: 0.15880\n",
      "Main effects training epoch: 6, train loss: 0.15993, val loss: 0.15846\n",
      "Main effects training epoch: 7, train loss: 0.15988, val loss: 0.15845\n",
      "Main effects training epoch: 8, train loss: 0.15981, val loss: 0.15832\n",
      "Main effects training epoch: 9, train loss: 0.15983, val loss: 0.15836\n",
      "Main effects training epoch: 10, train loss: 0.16014, val loss: 0.15864\n",
      "Main effects training epoch: 11, train loss: 0.15990, val loss: 0.15849\n",
      "Main effects training epoch: 12, train loss: 0.16005, val loss: 0.15861\n",
      "Main effects training epoch: 13, train loss: 0.16029, val loss: 0.15886\n",
      "Main effects training epoch: 14, train loss: 0.15982, val loss: 0.15838\n",
      "Main effects training epoch: 15, train loss: 0.15975, val loss: 0.15828\n",
      "Main effects training epoch: 16, train loss: 0.15978, val loss: 0.15837\n",
      "Main effects training epoch: 17, train loss: 0.15979, val loss: 0.15837\n",
      "Main effects training epoch: 18, train loss: 0.15979, val loss: 0.15831\n",
      "Main effects training epoch: 19, train loss: 0.15981, val loss: 0.15840\n",
      "Main effects training epoch: 20, train loss: 0.15981, val loss: 0.15836\n",
      "##########Stage 1: main effect training stop.##########\n",
      "12 main effects are pruned, start tuning.##########\n",
      "Main effects tuning epoch: 1, train loss: 0.16039, val loss: 0.15879\n",
      "Main effects tuning epoch: 2, train loss: 0.16110, val loss: 0.15964\n",
      "Main effects tuning epoch: 3, train loss: 0.16016, val loss: 0.15854\n",
      "Main effects tuning epoch: 4, train loss: 0.16008, val loss: 0.15850\n",
      "Main effects tuning epoch: 5, train loss: 0.15990, val loss: 0.15834\n",
      "Main effects tuning epoch: 6, train loss: 0.15992, val loss: 0.15841\n",
      "Main effects tuning epoch: 7, train loss: 0.15987, val loss: 0.15825\n",
      "Main effects tuning epoch: 8, train loss: 0.15993, val loss: 0.15842\n",
      "Main effects tuning epoch: 9, train loss: 0.15993, val loss: 0.15841\n",
      "Main effects tuning epoch: 10, train loss: 0.16001, val loss: 0.15833\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.14694, val loss: 0.14545\n",
      "Interaction training epoch: 2, train loss: 0.14583, val loss: 0.14417\n",
      "Interaction training epoch: 3, train loss: 0.14556, val loss: 0.14401\n",
      "Interaction training epoch: 4, train loss: 0.14542, val loss: 0.14363\n",
      "Interaction training epoch: 5, train loss: 0.14500, val loss: 0.14338\n",
      "Interaction training epoch: 6, train loss: 0.14506, val loss: 0.14350\n",
      "Interaction training epoch: 7, train loss: 0.14456, val loss: 0.14301\n",
      "Interaction training epoch: 8, train loss: 0.14477, val loss: 0.14302\n",
      "Interaction training epoch: 9, train loss: 0.14459, val loss: 0.14303\n",
      "Interaction training epoch: 10, train loss: 0.14478, val loss: 0.14323\n",
      "Interaction training epoch: 11, train loss: 0.14469, val loss: 0.14299\n",
      "Interaction training epoch: 12, train loss: 0.14464, val loss: 0.14325\n",
      "Interaction training epoch: 13, train loss: 0.14438, val loss: 0.14286\n",
      "Interaction training epoch: 14, train loss: 0.14428, val loss: 0.14270\n",
      "Interaction training epoch: 15, train loss: 0.14455, val loss: 0.14315\n",
      "Interaction training epoch: 16, train loss: 0.14405, val loss: 0.14300\n",
      "Interaction training epoch: 17, train loss: 0.14416, val loss: 0.14281\n",
      "Interaction training epoch: 18, train loss: 0.14390, val loss: 0.14274\n",
      "Interaction training epoch: 19, train loss: 0.14375, val loss: 0.14245\n",
      "Interaction training epoch: 20, train loss: 0.14367, val loss: 0.14269\n",
      "##########Stage 2: interaction training stop.##########\n",
      "##########3 interactions are pruned, start tuning.##########\n",
      "Interaction tuning epoch: 1, train loss: 0.14388, val loss: 0.14266\n",
      "Interaction tuning epoch: 2, train loss: 0.14370, val loss: 0.14265\n",
      "Interaction tuning epoch: 3, train loss: 0.14402, val loss: 0.14307\n",
      "Interaction tuning epoch: 4, train loss: 0.14387, val loss: 0.14284\n",
      "Interaction tuning epoch: 5, train loss: 0.14395, val loss: 0.14291\n",
      "Interaction tuning epoch: 6, train loss: 0.14330, val loss: 0.14253\n",
      "Interaction tuning epoch: 7, train loss: 0.14372, val loss: 0.14301\n",
      "Interaction tuning epoch: 8, train loss: 0.14362, val loss: 0.14248\n",
      "Interaction tuning epoch: 9, train loss: 0.14352, val loss: 0.14284\n",
      "Interaction tuning epoch: 10, train loss: 0.14319, val loss: 0.14253\n",
      "####################GAMI-Net training finished.####################\n",
      "time cost: 399.1959602832794\n",
      "After the gam stage, training error is 0.14319 , validation error is 0.14253\n",
      "missing value counts: 242286\n",
      "[SoftImpute] Max Singular Value of X_init = 79.490206\n",
      "#####mf_training#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 1: observed BCE=0.060165 validation BCE=0.127929,rank=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 2: observed BCE=0.058134 validation BCE=0.129523,rank=3\n",
      "[SoftImpute] Iter 3: observed BCE=0.062444 validation BCE=0.130851,rank=3\n",
      "[SoftImpute] Iter 4: observed BCE=0.062575 validation BCE=0.132075,rank=3\n",
      "[SoftImpute] Stopped after iteration 4 for lambda=1.589804\n",
      "final num of user group: 7\n",
      "final num of item group: 6\n",
      "change mode state : True\n",
      "time cost: 6.3516669273376465\n",
      "After the matrix factor stage, training error is 0.06258, validation error is 0.13208\n",
      "6\n",
      "ListWrapper(['ind_empleado', 'sex', 'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente', 'segmento', 'pais_residencia', 'canal_entrada', 'age', 'cust_seniority', 'income', 'marriage', 'item'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.16020, val loss: 0.16217\n",
      "Main effects training epoch: 2, train loss: 0.16094, val loss: 0.16311\n",
      "Main effects training epoch: 3, train loss: 0.16106, val loss: 0.16317\n",
      "Main effects training epoch: 4, train loss: 0.15952, val loss: 0.16159\n",
      "Main effects training epoch: 5, train loss: 0.15951, val loss: 0.16160\n",
      "Main effects training epoch: 6, train loss: 0.16011, val loss: 0.16206\n",
      "Main effects training epoch: 7, train loss: 0.15976, val loss: 0.16174\n",
      "Main effects training epoch: 8, train loss: 0.16021, val loss: 0.16215\n",
      "Main effects training epoch: 9, train loss: 0.15942, val loss: 0.16153\n",
      "Main effects training epoch: 10, train loss: 0.15939, val loss: 0.16147\n",
      "Main effects training epoch: 11, train loss: 0.15951, val loss: 0.16152\n",
      "Main effects training epoch: 12, train loss: 0.15965, val loss: 0.16177\n",
      "Main effects training epoch: 13, train loss: 0.15947, val loss: 0.16137\n",
      "Main effects training epoch: 14, train loss: 0.15932, val loss: 0.16134\n",
      "Main effects training epoch: 15, train loss: 0.15931, val loss: 0.16132\n",
      "Main effects training epoch: 16, train loss: 0.16122, val loss: 0.16342\n",
      "Main effects training epoch: 17, train loss: 0.15930, val loss: 0.16138\n",
      "Main effects training epoch: 18, train loss: 0.15934, val loss: 0.16149\n",
      "Main effects training epoch: 19, train loss: 0.15931, val loss: 0.16140\n",
      "Main effects training epoch: 20, train loss: 0.15935, val loss: 0.16143\n",
      "##########Stage 1: main effect training stop.##########\n",
      "11 main effects are pruned, start tuning.##########\n",
      "Main effects tuning epoch: 1, train loss: 0.15987, val loss: 0.16178\n",
      "Main effects tuning epoch: 2, train loss: 0.15935, val loss: 0.16131\n",
      "Main effects tuning epoch: 3, train loss: 0.15939, val loss: 0.16134\n",
      "Main effects tuning epoch: 4, train loss: 0.15972, val loss: 0.16171\n",
      "Main effects tuning epoch: 5, train loss: 0.15944, val loss: 0.16136\n",
      "Main effects tuning epoch: 6, train loss: 0.15949, val loss: 0.16155\n",
      "Main effects tuning epoch: 7, train loss: 0.15942, val loss: 0.16142\n",
      "Main effects tuning epoch: 8, train loss: 0.15942, val loss: 0.16153\n",
      "Main effects tuning epoch: 9, train loss: 0.15949, val loss: 0.16147\n",
      "Main effects tuning epoch: 10, train loss: 0.16042, val loss: 0.16234\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.14678, val loss: 0.14841\n",
      "Interaction training epoch: 2, train loss: 0.14550, val loss: 0.14742\n",
      "Interaction training epoch: 3, train loss: 0.14527, val loss: 0.14702\n",
      "Interaction training epoch: 4, train loss: 0.14543, val loss: 0.14720\n",
      "Interaction training epoch: 5, train loss: 0.14490, val loss: 0.14660\n",
      "Interaction training epoch: 6, train loss: 0.14474, val loss: 0.14674\n",
      "Interaction training epoch: 7, train loss: 0.14478, val loss: 0.14671\n",
      "Interaction training epoch: 8, train loss: 0.14457, val loss: 0.14649\n",
      "Interaction training epoch: 9, train loss: 0.14482, val loss: 0.14672\n",
      "Interaction training epoch: 10, train loss: 0.14461, val loss: 0.14655\n",
      "Interaction training epoch: 11, train loss: 0.14420, val loss: 0.14610\n",
      "Interaction training epoch: 12, train loss: 0.14422, val loss: 0.14610\n",
      "Interaction training epoch: 13, train loss: 0.14438, val loss: 0.14624\n",
      "Interaction training epoch: 14, train loss: 0.14393, val loss: 0.14587\n",
      "Interaction training epoch: 15, train loss: 0.14409, val loss: 0.14608\n",
      "Interaction training epoch: 16, train loss: 0.14386, val loss: 0.14587\n",
      "Interaction training epoch: 17, train loss: 0.14407, val loss: 0.14607\n",
      "Interaction training epoch: 18, train loss: 0.14364, val loss: 0.14579\n",
      "Interaction training epoch: 19, train loss: 0.14363, val loss: 0.14563\n",
      "Interaction training epoch: 20, train loss: 0.14370, val loss: 0.14559\n",
      "##########Stage 2: interaction training stop.##########\n",
      "##########2 interactions are pruned, start tuning.##########\n",
      "Interaction tuning epoch: 1, train loss: 0.14371, val loss: 0.14573\n",
      "Interaction tuning epoch: 2, train loss: 0.14344, val loss: 0.14551\n",
      "Interaction tuning epoch: 3, train loss: 0.14354, val loss: 0.14577\n",
      "Interaction tuning epoch: 4, train loss: 0.14335, val loss: 0.14569\n",
      "Interaction tuning epoch: 5, train loss: 0.14337, val loss: 0.14553\n",
      "Interaction tuning epoch: 6, train loss: 0.14310, val loss: 0.14523\n",
      "Interaction tuning epoch: 7, train loss: 0.14351, val loss: 0.14568\n",
      "Interaction tuning epoch: 8, train loss: 0.14301, val loss: 0.14527\n",
      "Interaction tuning epoch: 9, train loss: 0.14335, val loss: 0.14564\n",
      "Interaction tuning epoch: 10, train loss: 0.14294, val loss: 0.14513\n",
      "####################GAMI-Net training finished.####################\n",
      "time cost: 412.9299101829529\n",
      "After the gam stage, training error is 0.14294 , validation error is 0.14513\n",
      "missing value counts: 242286\n",
      "[SoftImpute] Max Singular Value of X_init = 79.445584\n",
      "#####mf_training#####\n",
      "[SoftImpute] Iter 1: observed BCE=0.063489 validation BCE=0.131680,rank=3\n",
      "[SoftImpute] Iter 2: observed BCE=0.063391 validation BCE=0.132758,rank=3\n",
      "[SoftImpute] Iter 3: observed BCE=0.062781 validation BCE=0.135980,rank=3\n",
      "[SoftImpute] Iter 4: observed BCE=0.063362 validation BCE=0.136641,rank=3\n",
      "[SoftImpute] Stopped after iteration 4 for lambda=1.588912\n",
      "final num of user group: 6\n",
      "final num of item group: 5\n",
      "change mode state : True\n",
      "time cost: 5.454999208450317\n",
      "After the matrix factor stage, training error is 0.06336, validation error is 0.13664\n",
      "7\n",
      "ListWrapper(['ind_empleado', 'sex', 'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente', 'segmento', 'pais_residencia', 'canal_entrada', 'age', 'cust_seniority', 'income', 'marriage', 'item'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.16111, val loss: 0.15957\n",
      "Main effects training epoch: 2, train loss: 0.16027, val loss: 0.15871\n",
      "Main effects training epoch: 3, train loss: 0.16003, val loss: 0.15856\n",
      "Main effects training epoch: 4, train loss: 0.16021, val loss: 0.15883\n",
      "Main effects training epoch: 5, train loss: 0.15989, val loss: 0.15837\n",
      "Main effects training epoch: 6, train loss: 0.15985, val loss: 0.15821\n",
      "Main effects training epoch: 7, train loss: 0.15997, val loss: 0.15853\n",
      "Main effects training epoch: 8, train loss: 0.16008, val loss: 0.15867\n",
      "Main effects training epoch: 9, train loss: 0.16001, val loss: 0.15846\n",
      "Main effects training epoch: 10, train loss: 0.15994, val loss: 0.15843\n",
      "Main effects training epoch: 11, train loss: 0.15978, val loss: 0.15823\n",
      "Main effects training epoch: 12, train loss: 0.15980, val loss: 0.15825\n",
      "Main effects training epoch: 13, train loss: 0.15996, val loss: 0.15833\n",
      "Main effects training epoch: 14, train loss: 0.15985, val loss: 0.15820\n",
      "Main effects training epoch: 15, train loss: 0.15975, val loss: 0.15819\n",
      "Main effects training epoch: 16, train loss: 0.15987, val loss: 0.15825\n",
      "Main effects training epoch: 17, train loss: 0.15978, val loss: 0.15824\n",
      "Main effects training epoch: 18, train loss: 0.15984, val loss: 0.15830\n",
      "Main effects training epoch: 19, train loss: 0.16002, val loss: 0.15842\n",
      "Main effects training epoch: 20, train loss: 0.15981, val loss: 0.15823\n",
      "##########Stage 1: main effect training stop.##########\n",
      "12 main effects are pruned, start tuning.##########\n",
      "Main effects tuning epoch: 1, train loss: 0.15982, val loss: 0.15835\n",
      "Main effects tuning epoch: 2, train loss: 0.15993, val loss: 0.15839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects tuning epoch: 3, train loss: 0.16018, val loss: 0.15860\n",
      "Main effects tuning epoch: 4, train loss: 0.16012, val loss: 0.15855\n",
      "Main effects tuning epoch: 5, train loss: 0.15991, val loss: 0.15844\n",
      "Main effects tuning epoch: 6, train loss: 0.16080, val loss: 0.15905\n",
      "Main effects tuning epoch: 7, train loss: 0.15985, val loss: 0.15837\n",
      "Main effects tuning epoch: 8, train loss: 0.15983, val loss: 0.15834\n",
      "Main effects tuning epoch: 9, train loss: 0.16005, val loss: 0.15869\n",
      "Main effects tuning epoch: 10, train loss: 0.15983, val loss: 0.15837\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.14708, val loss: 0.14553\n",
      "Interaction training epoch: 2, train loss: 0.14600, val loss: 0.14530\n",
      "Interaction training epoch: 3, train loss: 0.14629, val loss: 0.14533\n",
      "Interaction training epoch: 4, train loss: 0.14503, val loss: 0.14443\n",
      "Interaction training epoch: 5, train loss: 0.14538, val loss: 0.14494\n",
      "Interaction training epoch: 6, train loss: 0.14495, val loss: 0.14451\n",
      "Interaction training epoch: 7, train loss: 0.14450, val loss: 0.14420\n",
      "Interaction training epoch: 8, train loss: 0.14442, val loss: 0.14394\n",
      "Interaction training epoch: 9, train loss: 0.14451, val loss: 0.14439\n",
      "Interaction training epoch: 10, train loss: 0.14433, val loss: 0.14407\n",
      "Interaction training epoch: 11, train loss: 0.14412, val loss: 0.14396\n",
      "Interaction training epoch: 12, train loss: 0.14399, val loss: 0.14378\n",
      "Interaction training epoch: 13, train loss: 0.14389, val loss: 0.14362\n",
      "Interaction training epoch: 14, train loss: 0.14395, val loss: 0.14400\n",
      "Interaction training epoch: 15, train loss: 0.14423, val loss: 0.14428\n",
      "Interaction training epoch: 16, train loss: 0.14423, val loss: 0.14391\n",
      "Interaction training epoch: 17, train loss: 0.14389, val loss: 0.14352\n",
      "Interaction training epoch: 18, train loss: 0.14389, val loss: 0.14387\n",
      "Interaction training epoch: 19, train loss: 0.14440, val loss: 0.14445\n",
      "Interaction training epoch: 20, train loss: 0.14401, val loss: 0.14419\n",
      "##########Stage 2: interaction training stop.##########\n",
      "##########3 interactions are pruned, start tuning.##########\n",
      "Interaction tuning epoch: 1, train loss: 0.14472, val loss: 0.14445\n",
      "Interaction tuning epoch: 2, train loss: 0.14458, val loss: 0.14465\n",
      "Interaction tuning epoch: 3, train loss: 0.14424, val loss: 0.14415\n",
      "Interaction tuning epoch: 4, train loss: 0.14461, val loss: 0.14452\n",
      "Interaction tuning epoch: 5, train loss: 0.14460, val loss: 0.14433\n",
      "Interaction tuning epoch: 6, train loss: 0.14445, val loss: 0.14431\n",
      "Interaction tuning epoch: 7, train loss: 0.14446, val loss: 0.14426\n",
      "Interaction tuning epoch: 8, train loss: 0.14437, val loss: 0.14392\n",
      "Interaction tuning epoch: 9, train loss: 0.14415, val loss: 0.14436\n",
      "Interaction tuning epoch: 10, train loss: 0.14444, val loss: 0.14463\n",
      "####################GAMI-Net training finished.####################\n",
      "time cost: 396.60338401794434\n",
      "After the gam stage, training error is 0.14444 , validation error is 0.14463\n",
      "missing value counts: 242286\n",
      "[SoftImpute] Max Singular Value of X_init = 79.478624\n",
      "#####mf_training#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 1: observed BCE=0.061641 validation BCE=0.127571,rank=3\n",
      "[SoftImpute] Iter 2: observed BCE=0.059788 validation BCE=0.128865,rank=3\n",
      "[SoftImpute] Iter 3: observed BCE=0.064245 validation BCE=0.131245,rank=3\n",
      "[SoftImpute] Iter 4: observed BCE=0.067121 validation BCE=0.129566,rank=3\n",
      "[SoftImpute] Iter 5: observed BCE=0.067376 validation BCE=0.129922,rank=3\n",
      "[SoftImpute] Iter 6: observed BCE=0.067371 validation BCE=0.130203,rank=3\n",
      "[SoftImpute] Stopped after iteration 6 for lambda=1.589572\n",
      "final num of user group: 5\n",
      "final num of item group: 5\n",
      "change mode state : True\n",
      "time cost: 8.558361053466797\n",
      "After the matrix factor stage, training error is 0.06737, validation error is 0.13020\n",
      "8\n",
      "ListWrapper(['ind_empleado', 'sex', 'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente', 'segmento', 'pais_residencia', 'canal_entrada', 'age', 'cust_seniority', 'income', 'marriage', 'item'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.16044, val loss: 0.16108\n",
      "Main effects training epoch: 2, train loss: 0.16031, val loss: 0.16095\n",
      "Main effects training epoch: 3, train loss: 0.15964, val loss: 0.16036\n",
      "Main effects training epoch: 4, train loss: 0.15987, val loss: 0.16058\n",
      "Main effects training epoch: 5, train loss: 0.15988, val loss: 0.16063\n",
      "Main effects training epoch: 6, train loss: 0.15960, val loss: 0.16024\n",
      "Main effects training epoch: 7, train loss: 0.15949, val loss: 0.16032\n",
      "Main effects training epoch: 8, train loss: 0.15990, val loss: 0.16079\n",
      "Main effects training epoch: 9, train loss: 0.15965, val loss: 0.16041\n",
      "Main effects training epoch: 10, train loss: 0.15974, val loss: 0.16054\n",
      "Main effects training epoch: 11, train loss: 0.15958, val loss: 0.16031\n",
      "Main effects training epoch: 12, train loss: 0.15947, val loss: 0.16027\n",
      "Main effects training epoch: 13, train loss: 0.15976, val loss: 0.16057\n",
      "Main effects training epoch: 14, train loss: 0.16042, val loss: 0.16113\n",
      "Main effects training epoch: 15, train loss: 0.15993, val loss: 0.16074\n",
      "Main effects training epoch: 16, train loss: 0.16042, val loss: 0.16116\n",
      "Main effects training epoch: 17, train loss: 0.15949, val loss: 0.16027\n",
      "Main effects training epoch: 18, train loss: 0.15944, val loss: 0.16025\n",
      "Main effects training epoch: 19, train loss: 0.15942, val loss: 0.16026\n",
      "Main effects training epoch: 20, train loss: 0.15959, val loss: 0.16046\n",
      "##########Stage 1: main effect training stop.##########\n",
      "14 main effects are pruned, start tuning.##########\n",
      "Main effects tuning epoch: 1, train loss: 0.15978, val loss: 0.16053\n",
      "Main effects tuning epoch: 2, train loss: 0.15964, val loss: 0.16040\n",
      "Main effects tuning epoch: 3, train loss: 0.15961, val loss: 0.16034\n",
      "Main effects tuning epoch: 4, train loss: 0.15960, val loss: 0.16029\n",
      "Main effects tuning epoch: 5, train loss: 0.15968, val loss: 0.16038\n",
      "Main effects tuning epoch: 6, train loss: 0.15958, val loss: 0.16034\n",
      "Main effects tuning epoch: 7, train loss: 0.15972, val loss: 0.16046\n",
      "Main effects tuning epoch: 8, train loss: 0.16028, val loss: 0.16105\n",
      "Main effects tuning epoch: 9, train loss: 0.15972, val loss: 0.16055\n",
      "Main effects tuning epoch: 10, train loss: 0.15971, val loss: 0.16048\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.14705, val loss: 0.14720\n",
      "Interaction training epoch: 2, train loss: 0.14576, val loss: 0.14573\n",
      "Interaction training epoch: 3, train loss: 0.14533, val loss: 0.14550\n",
      "Interaction training epoch: 4, train loss: 0.14499, val loss: 0.14532\n",
      "Interaction training epoch: 5, train loss: 0.14480, val loss: 0.14475\n",
      "Interaction training epoch: 6, train loss: 0.14483, val loss: 0.14508\n",
      "Interaction training epoch: 7, train loss: 0.14415, val loss: 0.14432\n",
      "Interaction training epoch: 8, train loss: 0.14457, val loss: 0.14464\n",
      "Interaction training epoch: 9, train loss: 0.14431, val loss: 0.14473\n",
      "Interaction training epoch: 10, train loss: 0.14421, val loss: 0.14443\n",
      "Interaction training epoch: 11, train loss: 0.14421, val loss: 0.14472\n",
      "Interaction training epoch: 12, train loss: 0.14407, val loss: 0.14503\n",
      "Interaction training epoch: 13, train loss: 0.14383, val loss: 0.14446\n",
      "Interaction training epoch: 14, train loss: 0.14411, val loss: 0.14466\n",
      "Interaction training epoch: 15, train loss: 0.14374, val loss: 0.14427\n",
      "Interaction training epoch: 16, train loss: 0.14391, val loss: 0.14492\n",
      "Interaction training epoch: 17, train loss: 0.14367, val loss: 0.14472\n",
      "Interaction training epoch: 18, train loss: 0.14338, val loss: 0.14423\n",
      "Interaction training epoch: 19, train loss: 0.14341, val loss: 0.14431\n",
      "Interaction training epoch: 20, train loss: 0.14363, val loss: 0.14443\n",
      "##########Stage 2: interaction training stop.##########\n",
      "##########4 interactions are pruned, start tuning.##########\n",
      "Interaction tuning epoch: 1, train loss: 0.14402, val loss: 0.14504\n",
      "Interaction tuning epoch: 2, train loss: 0.14402, val loss: 0.14497\n",
      "Interaction tuning epoch: 3, train loss: 0.14373, val loss: 0.14466\n",
      "Interaction tuning epoch: 4, train loss: 0.14358, val loss: 0.14492\n",
      "Interaction tuning epoch: 5, train loss: 0.14367, val loss: 0.14456\n",
      "Interaction tuning epoch: 6, train loss: 0.14364, val loss: 0.14448\n",
      "Interaction tuning epoch: 7, train loss: 0.14357, val loss: 0.14449\n",
      "Interaction tuning epoch: 8, train loss: 0.14387, val loss: 0.14475\n",
      "Interaction tuning epoch: 9, train loss: 0.14382, val loss: 0.14488\n",
      "Interaction tuning epoch: 10, train loss: 0.14368, val loss: 0.14501\n",
      "####################GAMI-Net training finished.####################\n",
      "time cost: 415.6664867401123\n",
      "After the gam stage, training error is 0.14368 , validation error is 0.14501\n",
      "missing value counts: 242286\n",
      "[SoftImpute] Max Singular Value of X_init = 79.520436\n",
      "#####mf_training#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 1: observed BCE=0.060703 validation BCE=0.130465,rank=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 2: observed BCE=0.058366 validation BCE=0.132802,rank=3\n",
      "[SoftImpute] Iter 3: observed BCE=0.060191 validation BCE=0.136552,rank=3\n",
      "[SoftImpute] Iter 4: observed BCE=0.059967 validation BCE=0.137879,rank=3\n",
      "[SoftImpute] Stopped after iteration 4 for lambda=1.590409\n",
      "final num of user group: 7\n",
      "final num of item group: 6\n",
      "change mode state : True\n",
      "time cost: 5.529951810836792\n",
      "After the matrix factor stage, training error is 0.05997, validation error is 0.13788\n",
      "9\n",
      "ListWrapper(['ind_empleado', 'sex', 'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente', 'segmento', 'pais_residencia', 'canal_entrada', 'age', 'cust_seniority', 'income', 'marriage', 'item'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.16064, val loss: 0.15932\n",
      "Main effects training epoch: 2, train loss: 0.16035, val loss: 0.15901\n",
      "Main effects training epoch: 3, train loss: 0.16084, val loss: 0.15941\n",
      "Main effects training epoch: 4, train loss: 0.16006, val loss: 0.15857\n",
      "Main effects training epoch: 5, train loss: 0.15999, val loss: 0.15853\n",
      "Main effects training epoch: 6, train loss: 0.16036, val loss: 0.15880\n",
      "Main effects training epoch: 7, train loss: 0.15983, val loss: 0.15835\n",
      "Main effects training epoch: 8, train loss: 0.15990, val loss: 0.15851\n",
      "Main effects training epoch: 9, train loss: 0.15988, val loss: 0.15844\n",
      "Main effects training epoch: 10, train loss: 0.16023, val loss: 0.15885\n",
      "Main effects training epoch: 11, train loss: 0.15986, val loss: 0.15834\n",
      "Main effects training epoch: 12, train loss: 0.15998, val loss: 0.15851\n",
      "Main effects training epoch: 13, train loss: 0.16030, val loss: 0.15890\n",
      "Main effects training epoch: 14, train loss: 0.15973, val loss: 0.15828\n",
      "Main effects training epoch: 15, train loss: 0.15983, val loss: 0.15841\n",
      "Main effects training epoch: 16, train loss: 0.15974, val loss: 0.15826\n",
      "Main effects training epoch: 17, train loss: 0.16015, val loss: 0.15863\n",
      "Main effects training epoch: 18, train loss: 0.16109, val loss: 0.15951\n",
      "Main effects training epoch: 19, train loss: 0.15981, val loss: 0.15838\n",
      "Main effects training epoch: 20, train loss: 0.15974, val loss: 0.15829\n",
      "##########Stage 1: main effect training stop.##########\n",
      "13 main effects are pruned, start tuning.##########\n",
      "Main effects tuning epoch: 1, train loss: 0.15990, val loss: 0.15825\n",
      "Main effects tuning epoch: 2, train loss: 0.16054, val loss: 0.15893\n",
      "Main effects tuning epoch: 3, train loss: 0.15995, val loss: 0.15833\n",
      "Main effects tuning epoch: 4, train loss: 0.16001, val loss: 0.15851\n",
      "Main effects tuning epoch: 5, train loss: 0.16017, val loss: 0.15857\n",
      "Main effects tuning epoch: 6, train loss: 0.16008, val loss: 0.15843\n",
      "Main effects tuning epoch: 7, train loss: 0.15989, val loss: 0.15825\n",
      "Main effects tuning epoch: 8, train loss: 0.16008, val loss: 0.15863\n",
      "Main effects tuning epoch: 9, train loss: 0.16052, val loss: 0.15898\n",
      "Main effects tuning epoch: 10, train loss: 0.16004, val loss: 0.15856\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.14659, val loss: 0.14558\n",
      "Interaction training epoch: 2, train loss: 0.14557, val loss: 0.14479\n",
      "Interaction training epoch: 3, train loss: 0.14533, val loss: 0.14453\n",
      "Interaction training epoch: 4, train loss: 0.14511, val loss: 0.14406\n",
      "Interaction training epoch: 5, train loss: 0.14484, val loss: 0.14382\n",
      "Interaction training epoch: 6, train loss: 0.14449, val loss: 0.14363\n",
      "Interaction training epoch: 7, train loss: 0.14474, val loss: 0.14389\n",
      "Interaction training epoch: 8, train loss: 0.14457, val loss: 0.14366\n",
      "Interaction training epoch: 9, train loss: 0.14463, val loss: 0.14400\n",
      "Interaction training epoch: 10, train loss: 0.14443, val loss: 0.14374\n",
      "Interaction training epoch: 11, train loss: 0.14429, val loss: 0.14356\n",
      "Interaction training epoch: 12, train loss: 0.14489, val loss: 0.14424\n",
      "Interaction training epoch: 13, train loss: 0.14436, val loss: 0.14365\n",
      "Interaction training epoch: 14, train loss: 0.14435, val loss: 0.14365\n",
      "Interaction training epoch: 15, train loss: 0.14401, val loss: 0.14332\n",
      "Interaction training epoch: 16, train loss: 0.14415, val loss: 0.14371\n",
      "Interaction training epoch: 17, train loss: 0.14429, val loss: 0.14382\n",
      "Interaction training epoch: 18, train loss: 0.14392, val loss: 0.14341\n",
      "Interaction training epoch: 19, train loss: 0.14400, val loss: 0.14360\n",
      "Interaction training epoch: 20, train loss: 0.14400, val loss: 0.14355\n",
      "##########Stage 2: interaction training stop.##########\n",
      "##########3 interactions are pruned, start tuning.##########\n",
      "Interaction tuning epoch: 1, train loss: 0.14389, val loss: 0.14333\n",
      "Interaction tuning epoch: 2, train loss: 0.14389, val loss: 0.14345\n",
      "Interaction tuning epoch: 3, train loss: 0.14392, val loss: 0.14339\n",
      "Interaction tuning epoch: 4, train loss: 0.14381, val loss: 0.14329\n",
      "Interaction tuning epoch: 5, train loss: 0.14385, val loss: 0.14355\n",
      "Interaction tuning epoch: 6, train loss: 0.14373, val loss: 0.14333\n",
      "Interaction tuning epoch: 7, train loss: 0.14402, val loss: 0.14367\n",
      "Interaction tuning epoch: 8, train loss: 0.14376, val loss: 0.14345\n",
      "Interaction tuning epoch: 9, train loss: 0.14383, val loss: 0.14339\n",
      "Interaction tuning epoch: 10, train loss: 0.14367, val loss: 0.14342\n",
      "####################GAMI-Net training finished.####################\n",
      "time cost: 406.41806530952454\n",
      "After the gam stage, training error is 0.14367 , validation error is 0.14342\n",
      "missing value counts: 242286\n",
      "[SoftImpute] Max Singular Value of X_init = 79.262782\n",
      "#####mf_training#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Iter 1: observed BCE=0.059794 validation BCE=0.128447,rank=3\n",
      "[SoftImpute] Iter 2: observed BCE=0.061279 validation BCE=0.129281,rank=3\n",
      "[SoftImpute] Iter 3: observed BCE=0.060511 validation BCE=0.131100,rank=3\n",
      "[SoftImpute] Iter 4: observed BCE=0.062672 validation BCE=0.132611,rank=3\n",
      "[SoftImpute] Stopped after iteration 4 for lambda=1.585256\n",
      "final num of user group: 6\n",
      "final num of item group: 7\n",
      "change mode state : True\n",
      "time cost: 6.35776424407959\n",
      "After the matrix factor stage, training error is 0.06267, validation error is 0.13261\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gaminet.utils import local_visualize\n",
    "from gaminet.utils import global_visualize_density\n",
    "from gaminet.utils import feature_importance_visualize\n",
    "from gaminet.utils import plot_trajectory\n",
    "from gaminet.utils import plot_regularization\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from lvxnn.LVXNN import LV_XNN\n",
    "from lvxnn.DataReader import data_initialize\n",
    "\n",
    "data= pd.read_csv('data/train.csv')\n",
    "train , test = train_test_split(data,test_size=0.2 ,random_state=2)\n",
    "\n",
    "list1 = data.columns\n",
    "meta_info = OrderedDict()\n",
    "\n",
    "for i in list1:\n",
    "    meta_info[i]={'type': 'categorical','source':'user'}\n",
    "meta_info['income']={\"type\":\"continues\",'source':'user'}\n",
    "meta_info['cust_seniority']={\"type\":\"continues\",'source':'user'}\n",
    "meta_info['age'] = {\"type\":\"continues\",'source':'user'}\n",
    "meta_info['item'] = {'type': 'categorical','source':'item'}\n",
    "meta_info['user_id']={\"type\":\"id\",'source':'user'}\n",
    "meta_info['item_id']={\"type\":\"id\",'source':'item'}\n",
    "meta_info['target']={\"type\":\"target\",'source':''}\n",
    "\n",
    "\n",
    "tr_x, tr_Xi, tr_y , te_x , te_Xi, te_y, meta_info, model_info = data_initialize(train,test,meta_info,\"Classification\")\n",
    "\n",
    "def auto_test():\n",
    "    cold_auc = []\n",
    "    cold_logloss = []\n",
    "    warm_auc = []\n",
    "    warm_logloss = []\n",
    "    gami_auc = []\n",
    "    gami_logloss = []\n",
    "\n",
    "    for times in range(10):\n",
    "        \n",
    "        print(times)\n",
    "\n",
    "\n",
    "        model = LV_XNN(model_info=model_info, meta_info=meta_info, subnet_arch=[8, 16],interact_arch=[20, 10],activation_func=tf.tanh, batch_size=1000, lr_bp=0.01, auto_tune=False,\n",
    "               interaction_epochs=20,main_effect_epochs=20,tuning_epochs=10,loss_threshold_main=0.01,loss_threshold_inter=0.01,alpha=0,\n",
    "              verbose=True,val_ratio=0.125, early_stop_thres=100,interact_num=10,u_group_num=10,i_group_num=20,scale_ratio=0.8,n_power_iterations=5,n_oversamples=0,\n",
    "              mf_training_iters=1,mf_tuning_iters=100,change_mode=True,convergence_threshold=0.001,max_rank=3,shrinkage_value=20, epsilon=0,random_state=times,combine_range=0.95)\n",
    "    \n",
    "        st_time = time.time()\n",
    "        model.fit(tr_x,tr_Xi, tr_y)\n",
    "        ed_time = time.time()\n",
    "        \n",
    "        pred = model.predict(te_x, te_Xi)\n",
    "        \n",
    "        cold_y = te_y[(te_Xi[:,1] == 'cold') | (te_Xi[:,0] == 'cold')]\n",
    "        cold_pred = pred[(te_Xi[:,1] == 'cold') | (te_Xi[:,0] == 'cold')]\n",
    "        warm_y = te_y[(te_Xi[:,1] != 'cold') & (te_Xi[:,0] != 'cold')]\n",
    "        warm_pred = pred[(te_Xi[:,1] != 'cold') & (te_Xi[:,0] != 'cold')]\n",
    "    \n",
    "        cold_auc.append(roc_auc_score(cold_y,cold_pred))\n",
    "        cold_logloss.append(log_loss(cold_y,cold_pred))\n",
    "        warm_auc.append(roc_auc_score(warm_y,warm_pred))\n",
    "        warm_logloss.append(log_loss(warm_y,warm_pred))\n",
    "        gami_auc.append(roc_auc_score(te_y,model.final_gam_model.predict(te_x)))\n",
    "        gami_logloss.append(log_loss(te_y,model.final_gam_model.predict(te_x)))\n",
    "        \n",
    "    i_result = np.array([np.mean(cold_auc),np.mean(cold_logloss),np.mean(warm_auc),np.mean(warm_logloss)]).reshape(1,-1)\n",
    "    result = pd.DataFrame(i_result,columns=['cold_auc','cold_logloss','warm_auc','warm_logloss'])\n",
    "    \n",
    "    g_result = np.array([np.mean(gami_auc),np.mean(gami_logloss)]).reshape(1,-1)\n",
    "    g_result = pd.DataFrame(g_result,columns=['auc','logloss'])\n",
    "    \n",
    "    return result, g_result\n",
    "\n",
    "results, g_result = (auto_test())\n",
    "results.to_csv('result/LVXNN_result.csv',index=None)\n",
    "g_result.to_csv('result/gami_result.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "data= pd.read_csv('data/train.csv')\n",
    "data = data.drop(['item'],1)\n",
    "train , test = train_test_split(data,test_size=0.2, random_state=2)\n",
    "data,val = train_test_split(train,test_size=0.125)\n",
    "\n",
    "x=data.iloc[:,:-1].values\n",
    "y=data.iloc[:,-1].values\n",
    "x_t = test.iloc[:,:-1].values\n",
    "y_t = test.iloc[:,-1].values\n",
    "\n",
    "enc = MinMaxScaler()\n",
    "x = enc.fit_transform(x)\n",
    "x_t = enc.fit_transform(x_t)\n",
    "\n",
    "def auto_test():\n",
    "    auc = []\n",
    "    logloss = []\n",
    "    for times in range(10):\n",
    "        xgb = XGBClassifier(n_jobs=-1)\n",
    "        xgb.fit(x,y)\n",
    "        pred = xgb.predict_proba(x_t)\n",
    "        \n",
    "        auc.append(roc_auc_score(y_t,pred[:,1]))\n",
    "        logloss.append(log_loss(y_t,pred[:,1]))\n",
    "\n",
    "    i_result = np.array([np.mean(auc),np.mean(logloss)]).reshape(1,-1)\n",
    "    result = pd.DataFrame(i_result,columns=['auc','logloss'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "results = (auto_test())\n",
    "results.to_csv('result/xgboost_result.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "data= pd.read_csv('data/train.csv')\n",
    "data = data.drop(['item'],1)\n",
    "train , test = train_test_split(data,test_size=0.2,random_state=2)\n",
    "data,val = train_test_split(train,test_size=0.125)\n",
    "\n",
    "Xi = data.iloc[:,-3:-1].values\n",
    "y = data.iloc[:,-1].values\n",
    "Xi_t = test.iloc[:,-3:-1].values\n",
    "y_t = test.iloc[:,-1].values\n",
    "\n",
    "tr_ratings_dict = {'itemID': Xi[:,1].tolist(),\n",
    "                'userID': Xi[:,0].tolist(),\n",
    "                'rating': y.tolist()}\n",
    "\n",
    "tr_df = pd.DataFrame(tr_ratings_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(y.min(), y.max()))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "tr_data = Dataset.load_from_df(tr_df[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "tr_data = tr_data.build_full_trainset()\n",
    "\n",
    "def auto_test():\n",
    "    auc = []\n",
    "    logloss = []\n",
    "    for j in range(10):\n",
    "        model = SVD(n_factors=3)\n",
    "\n",
    "        model.fit(tr_data)\n",
    "\n",
    "        pred = []\n",
    "        \n",
    "        for i in range(Xi_t.shape[0]):\n",
    "            pred.append(model.predict(Xi_t[i,0],Xi_t[i,1],Xi_t[i,0]).est)\n",
    "    \n",
    "        pred2 = np.array(pred).ravel()\n",
    "\n",
    "        auc.append(roc_auc_score(y_t,pred2))\n",
    "        logloss.append(log_loss(y_t,pred2))\n",
    "    \n",
    "    i_result = np.array([np.mean(auc),np.mean(logloss)]).reshape(1,-1)\n",
    "    result = pd.DataFrame(i_result,columns=['auc','logloss'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "results = (auto_test())\n",
    "results.to_csv('result/svd_result.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deepfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x0000014B8672B598>, 'loss_type': 'logloss', 'epoch': 10, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.1, 'verbose': True, 'eval_metric': <function log_loss at 0x0000014B9A90E1E0>, 'random_seed': 2017, 'feature_size': 64139, 'field_size': 20}\n",
      "#params: 259620\n",
      "[1] train-result=0.1544, valid-result=0.1696 [10.5 s]\n",
      "[2] train-result=0.1256, valid-result=0.1763 [9.6 s]\n",
      "[3] train-result=0.1079, valid-result=0.1849 [9.2 s]\n",
      "[4] train-result=0.0819, valid-result=0.1988 [9.4 s]\n",
      "[5] train-result=0.0567, valid-result=0.2208 [9.6 s]\n",
      "[6] train-result=0.0422, valid-result=0.2413 [11.1 s]\n",
      "[7] train-result=0.0347, valid-result=0.2520 [11.0 s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:2174: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] train-result=0.0294, valid-result=inf [10.0 s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:2174: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:2174: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] train-result=0.0252, valid-result=nan [10.3 s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:2174: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:2174: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:2174: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:2174: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] train-result=nan, valid-result=nan [10.0 s]\n",
      "#params: 259620\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d2ad057e2e7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m \u001b[0mresult_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mauto_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[0mresult_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mauto_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[0mresult_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result/deepfm_result.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-d2ad057e2e7f>\u001b[0m in \u001b[0;36mauto_test\u001b[1;34m(deep)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0my_train_dfm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_dfm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_base_model_dfm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdfTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdfm_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[0mauc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_dfm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mlogloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_dfm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-d2ad057e2e7f>\u001b[0m in \u001b[0;36m_run_base_model_dfm\u001b[1;34m(dfTrain, dfTest, folds, dfm_params)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mdfm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepFM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdfm_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mdfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXv_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXi_valid_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXv_valid_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0my_train_meta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi_valid_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXv_valid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\索信达\\代码\\lvxnn_0526\\scripts\\benchmark\\deepfm\\DeepFM.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, Xi_train, Xv_train, y_train, Xi_valid, Xv_valid, y_valid, early_stopping, refit)\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m                 \u001b[0mXi_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXv_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXv_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXv_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;31m# evaluate training and validation datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\索信达\\代码\\lvxnn_0526\\scripts\\benchmark\\deepfm\\DeepFM.py\u001b[0m in \u001b[0;36mfit_on_batch\u001b[1;34m(self, Xi, Xv, y)\u001b[0m\n\u001b[0;32m    258\u001b[0m                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_keep_deep\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_deep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                      self.train_phase: True}\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1163\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1165\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \"\"\"\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections_abc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \"\"\"\n\u001b[0;32m    374\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \"\"\"\n\u001b[0;32m    374\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    262\u001b[0m       raise TypeError('Fetch argument %r has invalid type %r' %\n\u001b[0;32m    263\u001b[0m                       (fetch, type(fetch)))\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class config():\n",
    "# set the path-to-files\n",
    "    \n",
    "    TRAIN_FILE = \"./data/train.csv\"\n",
    "    SUB_DIR = \"./result\"\n",
    "    NUM_SPLITS = 3\n",
    "    RANDOM_SEED = 2017\n",
    "\n",
    "# types of columns of the dataset dataframe\n",
    "    CATEGORICAL_COLS = [\"item\",\"ind_empleado\",\"sex\",\"indrel_1mes\",'tiprel_1mes','indresi','indext','indfall','ind_actividad_cliente','segmento','pais_residencia','canal_entrada']\n",
    "    NUMERIC_COLS = [\"ind_nuevo\", \"indrel\", \"age\", \"cust_seniority\"]\n",
    "    IGNORE_COLS = [\"target\"]\n",
    "    \n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('../benchmark/deepfm/')\n",
    "from DataReader import FeatureDictionary, DataParser\n",
    "from DeepFM import DeepFM\n",
    "\n",
    "\n",
    "def _load_data():\n",
    "\n",
    "    dfTrain = pd.read_csv(config.TRAIN_FILE)\n",
    "    dfTrain , dfTest = train_test_split(dfTrain,test_size=0.2,random_state=2)\n",
    "\n",
    "    def preprocess(df):        \n",
    "        cols = [c for c in df.columns if c not in [\"target\"]]\n",
    "        return df\n",
    "\n",
    "    dfTrain = preprocess(dfTrain)\n",
    "    dfTest = preprocess(dfTest)\n",
    "    cols = [c for c in dfTrain.columns if c not in [\"target\"]]\n",
    "\n",
    "\n",
    "    X_train = dfTrain[cols].values\n",
    "    y_train = dfTrain[\"target\"].values\n",
    "    X_test = dfTest[cols].values\n",
    "    \n",
    "    ids_test = dfTest[\"user_id\"].values\n",
    "    idv_test = dfTest[\"item_id\"].values\n",
    "    y_test = dfTest['target'].values\n",
    "        \n",
    "    return dfTrain, dfTest, X_train, y_train, X_test, ids_test,idv_test, y_test\n",
    "\n",
    "\n",
    "def _run_base_model_dfm(dfTrain, dfTest, folds, dfm_params):\n",
    "    fd = FeatureDictionary(dfTrain=dfTrain, dfTest=dfTest,\n",
    "                           numeric_cols=config.NUMERIC_COLS,\n",
    "                           ignore_cols=config.IGNORE_COLS)\n",
    "    data_parser = DataParser(feat_dict=fd)\n",
    "    Xi_train, Xv_train, y_train = data_parser.parse(df=dfTrain, has_label=True)\n",
    "    Xi_test, Xv_test, ids_test,idv_test = data_parser.parse(df=dfTest)\n",
    "    \n",
    "    dfm_params[\"feature_size\"] = fd.feat_dim\n",
    "    dfm_params[\"field_size\"] = len(Xi_train[0])\n",
    "    print(dfm_params)\n",
    "\n",
    "    y_train_meta = np.zeros((dfTrain.shape[0], 1), dtype=float)\n",
    "    y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)\n",
    "    _get = lambda x, l: [x[i] for i in l]\n",
    "    gini_results_cv = np.zeros(len(folds), dtype=float)\n",
    "    gini_results_epoch_train = np.zeros((len(folds), dfm_params[\"epoch\"]), dtype=float)\n",
    "    gini_results_epoch_valid = np.zeros((len(folds), dfm_params[\"epoch\"]), dtype=float)\n",
    "    for i, (train_idx, valid_idx) in enumerate(folds):\n",
    "        Xi_train_, Xv_train_, y_train_ = _get(Xi_train, train_idx), _get(Xv_train, train_idx), _get(y_train, train_idx)\n",
    "        Xi_valid_, Xv_valid_, y_valid_ = _get(Xi_train, valid_idx), _get(Xv_train, valid_idx), _get(y_train, valid_idx)\n",
    "\n",
    "        dfm = DeepFM(**dfm_params)\n",
    "        dfm.fit(Xi_train_, Xv_train_, y_train_, Xi_valid_, Xv_valid_, y_valid_)\n",
    "\n",
    "        y_train_meta[valid_idx,0] = dfm.predict(Xi_valid_, Xv_valid_)\n",
    "        y_test_meta[:,0] += dfm.predict(Xi_test, Xv_test)\n",
    "        \n",
    "        gini_results_cv[i] = mean_absolute_error(y_valid_, y_train_meta[valid_idx])\n",
    "        gini_results_epoch_train[i] = dfm.train_result\n",
    "        gini_results_epoch_valid[i] = dfm.valid_result\n",
    "\n",
    "    y_test_meta /= float(len(folds))\n",
    "\n",
    "    # save result\n",
    "    return y_train_meta, y_test_meta\n",
    "\n",
    "# load data\n",
    "dfTrain, dfTest, X_train, y_train, X_test, ids_test ,idv_test, y_test= _load_data()\n",
    "\n",
    "# folds\n",
    "folds = list(KFold(n_splits=config.NUM_SPLITS, shuffle=True,\n",
    "                             random_state=config.RANDOM_SEED).split(X_train, y_train))\n",
    "\n",
    "\n",
    "\n",
    "# ------------------ DeepFM Model ------------------\n",
    "# params\n",
    "dfm_params = {\n",
    "    \"embedding_size\": 3,\n",
    "    \"deep_layers\": [32, 32],\n",
    "    \"use_deep\" : True ,\n",
    "    \"use_fm\" : True , \n",
    "    \"deep_layers_activation\": tf.nn.relu,\n",
    "    \"loss_type\" : \"logloss\",\n",
    "    \"epoch\": 10 ,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"optimizer_type\": \"adam\",\n",
    "    \"batch_norm\": 0,\n",
    "    \"batch_norm_decay\": 0.995,\n",
    "    \"l2_reg\": 0.1,\n",
    "    \"verbose\": True,\n",
    "    \"eval_metric\": log_loss,\n",
    "    \"random_seed\": config.RANDOM_SEED\n",
    "}\n",
    "\n",
    "def auto_test(deep):\n",
    "    auc = []\n",
    "    logloss = []\n",
    "    dfm_params['use_deep']=deep\n",
    "    \n",
    "    for i in range(10):\n",
    "        y_train_dfm, y_test_dfm = _run_base_model_dfm(dfTrain, dfTest, folds, dfm_params)\n",
    "        auc.append(roc_auc_score(y_test,y_test_dfm))\n",
    "        logloss.append(log_loss(y_test,y_test_dfm))\n",
    "    \n",
    "    i_result = np.array([np.mean(auc),np.mean(logloss)]).reshape(1,-1)\n",
    "    results = pd.DataFrame(i_result,columns=['auc','logloss'])\n",
    "    \n",
    "    return results\n",
    "result_1 = (auto_test(True))\n",
    "result_2 = (auto_test(False))\n",
    "result_1.to_csv('result/deepfm_result.csv',index=None)\n",
    "result_2.to_csv('result/fm_result.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
