{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0622 13:51:04.768366  2964 deprecation.py:323] From C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lvxnn_test import lvxnn\n",
    "from xgb_test import xgb\n",
    "from svd_test import svd\n",
    "from collections import OrderedDict\n",
    "from deepfm_fm_test import deepfm_fm\n",
    "import time\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from sklearn.metrics import mean_squared_error,roc_auc_score,mean_absolute_error,log_loss\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from lvxnn.LVXNN import LV_XNN\n",
    "from lvxnn.DataReader import data_initialize\n",
    "\n",
    "data= pd.read_csv('../simulation/data/sim_0.9.csv')\n",
    "train , test = train_test_split(data,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info = OrderedDict()\n",
    "\n",
    "meta_info['uf_1']={'type': 'continues','source':'user'}\n",
    "meta_info['uf_2']={'type': 'continues','source':'user'}\n",
    "meta_info['uf_3']={'type': 'continues','source':'user'}\n",
    "meta_info['uf_4']={'type': 'continues','source':'user'}\n",
    "meta_info['uf_5']={'type': 'continues','source':'user'}\n",
    "meta_info['if_1']={'type': 'continues','source':'item'}\n",
    "meta_info['if_2']={'type': 'continues','source':'item'}\n",
    "meta_info['if_3']={'type': 'continues','source':'item'}\n",
    "meta_info['if_4']={'type': 'continues','source':'item'}\n",
    "meta_info['if_5']={'type': 'continues','source':'item'}\n",
    "meta_info['user_id']={\"type\":\"id\",'source':'user'}\n",
    "meta_info['item_id']={\"type\":\"id\",'source':'item'}\n",
    "meta_info['target']={\"type\":\"target\",'source':''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\lvxnn\\DataReader.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.26 MB\n",
      "Decreased by 69.6%\n",
      "Memory usage of dataframe is 0.21 MB\n",
      "Memory usage after optimization is: 0.07 MB\n",
      "Decreased by 69.6%\n",
      "cold start user: 36\n",
      "cold start item: 317\n",
      "0\n",
      "ListWrapper(['uf_1', 'uf_2', 'uf_3', 'uf_4', 'uf_5', 'if_1', 'if_2', 'if_3', 'if_4', 'if_5'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 4.02581, val loss: 4.15569\n",
      "Main effects training epoch: 2, train loss: 3.86663, val loss: 4.00300\n",
      "Main effects training epoch: 3, train loss: 3.66700, val loss: 3.81314\n",
      "Main effects training epoch: 4, train loss: 3.48207, val loss: 3.63384\n",
      "Main effects training epoch: 5, train loss: 3.38250, val loss: 3.50337\n",
      "Main effects training epoch: 6, train loss: 3.28135, val loss: 3.35840\n",
      "Main effects training epoch: 7, train loss: 3.28186, val loss: 3.35070\n",
      "Main effects training epoch: 8, train loss: 3.27336, val loss: 3.36040\n",
      "Main effects training epoch: 9, train loss: 3.25283, val loss: 3.34172\n",
      "Main effects training epoch: 10, train loss: 3.15250, val loss: 3.23796\n",
      "Main effects training epoch: 11, train loss: 3.05938, val loss: 3.14667\n",
      "Main effects training epoch: 12, train loss: 3.05048, val loss: 3.13776\n",
      "Main effects training epoch: 13, train loss: 2.97453, val loss: 3.06166\n",
      "Main effects training epoch: 14, train loss: 2.90463, val loss: 2.99088\n",
      "Main effects training epoch: 15, train loss: 2.85090, val loss: 2.93330\n",
      "Main effects training epoch: 16, train loss: 2.80705, val loss: 2.88247\n",
      "Main effects training epoch: 17, train loss: 2.72197, val loss: 2.79421\n",
      "Main effects training epoch: 18, train loss: 2.70970, val loss: 2.78070\n",
      "Main effects training epoch: 19, train loss: 2.64818, val loss: 2.71541\n",
      "Main effects training epoch: 20, train loss: 2.60938, val loss: 2.68330\n",
      "Main effects training epoch: 21, train loss: 2.57306, val loss: 2.65275\n",
      "Main effects training epoch: 22, train loss: 2.51936, val loss: 2.59316\n",
      "Main effects training epoch: 23, train loss: 2.51905, val loss: 2.60367\n",
      "Main effects training epoch: 24, train loss: 2.44088, val loss: 2.52255\n",
      "Main effects training epoch: 25, train loss: 2.41554, val loss: 2.50227\n",
      "Main effects training epoch: 26, train loss: 2.38866, val loss: 2.46996\n",
      "Main effects training epoch: 27, train loss: 2.36765, val loss: 2.45355\n",
      "Main effects training epoch: 28, train loss: 2.33153, val loss: 2.41112\n",
      "Main effects training epoch: 29, train loss: 2.28303, val loss: 2.36249\n",
      "Main effects training epoch: 30, train loss: 2.26930, val loss: 2.35093\n",
      "Main effects training epoch: 31, train loss: 2.21173, val loss: 2.29201\n",
      "Main effects training epoch: 32, train loss: 2.24060, val loss: 2.32154\n",
      "Main effects training epoch: 33, train loss: 2.17058, val loss: 2.25252\n",
      "Main effects training epoch: 34, train loss: 2.18446, val loss: 2.25689\n",
      "Main effects training epoch: 35, train loss: 2.16814, val loss: 2.24363\n",
      "Main effects training epoch: 36, train loss: 2.13803, val loss: 2.21848\n",
      "Main effects training epoch: 37, train loss: 2.07828, val loss: 2.15467\n",
      "Main effects training epoch: 38, train loss: 2.10415, val loss: 2.17893\n",
      "Main effects training epoch: 39, train loss: 2.06347, val loss: 2.14620\n",
      "Main effects training epoch: 40, train loss: 2.05131, val loss: 2.12958\n",
      "Main effects training epoch: 41, train loss: 2.04399, val loss: 2.11796\n",
      "Main effects training epoch: 42, train loss: 1.99832, val loss: 2.07447\n",
      "Main effects training epoch: 43, train loss: 1.99686, val loss: 2.07381\n",
      "Main effects training epoch: 44, train loss: 1.98219, val loss: 2.05986\n",
      "Main effects training epoch: 45, train loss: 1.98538, val loss: 2.06555\n",
      "Main effects training epoch: 46, train loss: 1.93199, val loss: 2.00777\n",
      "Main effects training epoch: 47, train loss: 1.92633, val loss: 2.00292\n",
      "Main effects training epoch: 48, train loss: 1.93781, val loss: 2.01180\n",
      "Main effects training epoch: 49, train loss: 1.90558, val loss: 1.97629\n",
      "Main effects training epoch: 50, train loss: 1.89436, val loss: 1.97301\n",
      "Main effects training epoch: 51, train loss: 1.88707, val loss: 1.95539\n",
      "Main effects training epoch: 52, train loss: 1.87418, val loss: 1.95203\n",
      "Main effects training epoch: 53, train loss: 1.88074, val loss: 1.95203\n",
      "Main effects training epoch: 54, train loss: 1.84766, val loss: 1.91670\n",
      "Main effects training epoch: 55, train loss: 1.86362, val loss: 1.93316\n",
      "Main effects training epoch: 56, train loss: 1.84504, val loss: 1.91578\n",
      "Main effects training epoch: 57, train loss: 1.83871, val loss: 1.90598\n",
      "Main effects training epoch: 58, train loss: 1.83635, val loss: 1.90794\n",
      "Main effects training epoch: 59, train loss: 1.81987, val loss: 1.88301\n",
      "Main effects training epoch: 60, train loss: 1.81411, val loss: 1.87753\n",
      "Main effects training epoch: 61, train loss: 1.79435, val loss: 1.85428\n",
      "Main effects training epoch: 62, train loss: 1.80737, val loss: 1.87724\n",
      "Main effects training epoch: 63, train loss: 1.78433, val loss: 1.84476\n",
      "Main effects training epoch: 64, train loss: 1.77484, val loss: 1.83380\n",
      "Main effects training epoch: 65, train loss: 1.76469, val loss: 1.82684\n",
      "Main effects training epoch: 66, train loss: 1.75610, val loss: 1.81696\n",
      "Main effects training epoch: 67, train loss: 1.74015, val loss: 1.80136\n",
      "Main effects training epoch: 68, train loss: 1.74855, val loss: 1.80547\n",
      "Main effects training epoch: 69, train loss: 1.73357, val loss: 1.79520\n",
      "Main effects training epoch: 70, train loss: 1.74203, val loss: 1.79823\n",
      "Main effects training epoch: 71, train loss: 1.73003, val loss: 1.79278\n",
      "Main effects training epoch: 72, train loss: 1.72470, val loss: 1.77914\n",
      "Main effects training epoch: 73, train loss: 1.72740, val loss: 1.78702\n",
      "Main effects training epoch: 74, train loss: 1.71997, val loss: 1.77884\n",
      "Main effects training epoch: 75, train loss: 1.72546, val loss: 1.77572\n",
      "Main effects training epoch: 76, train loss: 1.71292, val loss: 1.77190\n",
      "Main effects training epoch: 77, train loss: 1.71444, val loss: 1.77190\n",
      "Main effects training epoch: 78, train loss: 1.71019, val loss: 1.76935\n",
      "Main effects training epoch: 79, train loss: 1.70637, val loss: 1.75924\n",
      "Main effects training epoch: 80, train loss: 1.70559, val loss: 1.76570\n",
      "Main effects training epoch: 81, train loss: 1.70424, val loss: 1.76163\n",
      "Main effects training epoch: 82, train loss: 1.69625, val loss: 1.75276\n",
      "Main effects training epoch: 83, train loss: 1.70362, val loss: 1.76509\n",
      "Main effects training epoch: 84, train loss: 1.69010, val loss: 1.74551\n",
      "Main effects training epoch: 85, train loss: 1.69095, val loss: 1.75028\n",
      "Main effects training epoch: 86, train loss: 1.68340, val loss: 1.74746\n",
      "Main effects training epoch: 87, train loss: 1.68064, val loss: 1.74529\n",
      "Main effects training epoch: 88, train loss: 1.67380, val loss: 1.74022\n",
      "Main effects training epoch: 89, train loss: 1.67360, val loss: 1.74665\n",
      "Main effects training epoch: 90, train loss: 1.65844, val loss: 1.73033\n",
      "Main effects training epoch: 91, train loss: 1.65355, val loss: 1.72703\n",
      "Main effects training epoch: 92, train loss: 1.64214, val loss: 1.71970\n",
      "Main effects training epoch: 93, train loss: 1.64936, val loss: 1.73062\n",
      "Main effects training epoch: 94, train loss: 1.63636, val loss: 1.71888\n",
      "Main effects training epoch: 95, train loss: 1.63488, val loss: 1.72091\n",
      "Main effects training epoch: 96, train loss: 1.63066, val loss: 1.70495\n",
      "Main effects training epoch: 97, train loss: 1.63836, val loss: 1.72648\n",
      "Main effects training epoch: 98, train loss: 1.63448, val loss: 1.71359\n",
      "Main effects training epoch: 99, train loss: 1.62205, val loss: 1.71122\n",
      "Main effects training epoch: 100, train loss: 1.62696, val loss: 1.71339\n",
      "Main effects training epoch: 101, train loss: 1.62468, val loss: 1.70969\n",
      "Main effects training epoch: 102, train loss: 1.62361, val loss: 1.71057\n",
      "Main effects training epoch: 103, train loss: 1.61811, val loss: 1.70932\n",
      "Main effects training epoch: 104, train loss: 1.61437, val loss: 1.69638\n",
      "Main effects training epoch: 105, train loss: 1.61687, val loss: 1.70838\n",
      "Main effects training epoch: 106, train loss: 1.61267, val loss: 1.69917\n",
      "Main effects training epoch: 107, train loss: 1.60933, val loss: 1.69456\n",
      "Main effects training epoch: 108, train loss: 1.60899, val loss: 1.69789\n",
      "Main effects training epoch: 109, train loss: 1.61071, val loss: 1.70213\n",
      "Main effects training epoch: 110, train loss: 1.60834, val loss: 1.69356\n",
      "Main effects training epoch: 111, train loss: 1.60903, val loss: 1.69018\n",
      "Main effects training epoch: 112, train loss: 1.61192, val loss: 1.71417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 113, train loss: 1.60321, val loss: 1.68930\n",
      "Main effects training epoch: 114, train loss: 1.60681, val loss: 1.69810\n",
      "Main effects training epoch: 115, train loss: 1.61161, val loss: 1.69664\n",
      "Main effects training epoch: 116, train loss: 1.60462, val loss: 1.69884\n",
      "Main effects training epoch: 117, train loss: 1.60153, val loss: 1.68634\n",
      "Main effects training epoch: 118, train loss: 1.59715, val loss: 1.69219\n",
      "Main effects training epoch: 119, train loss: 1.59567, val loss: 1.68591\n",
      "Main effects training epoch: 120, train loss: 1.59747, val loss: 1.68979\n",
      "Main effects training epoch: 121, train loss: 1.59275, val loss: 1.68562\n",
      "Main effects training epoch: 122, train loss: 1.58952, val loss: 1.68187\n",
      "Main effects training epoch: 123, train loss: 1.59299, val loss: 1.69392\n",
      "Main effects training epoch: 124, train loss: 1.58823, val loss: 1.67589\n",
      "Main effects training epoch: 125, train loss: 1.58752, val loss: 1.67897\n",
      "Main effects training epoch: 126, train loss: 1.58643, val loss: 1.67941\n",
      "Main effects training epoch: 127, train loss: 1.58719, val loss: 1.68306\n",
      "Main effects training epoch: 128, train loss: 1.58105, val loss: 1.67735\n",
      "Main effects training epoch: 129, train loss: 1.58516, val loss: 1.67262\n",
      "Main effects training epoch: 130, train loss: 1.57827, val loss: 1.67244\n",
      "Main effects training epoch: 131, train loss: 1.57854, val loss: 1.66952\n",
      "Main effects training epoch: 132, train loss: 1.58368, val loss: 1.67841\n",
      "Main effects training epoch: 133, train loss: 1.57787, val loss: 1.66421\n",
      "Main effects training epoch: 134, train loss: 1.57550, val loss: 1.67620\n",
      "Main effects training epoch: 135, train loss: 1.57558, val loss: 1.66555\n",
      "Main effects training epoch: 136, train loss: 1.57565, val loss: 1.66808\n",
      "Main effects training epoch: 137, train loss: 1.57215, val loss: 1.65359\n",
      "Main effects training epoch: 138, train loss: 1.57597, val loss: 1.67812\n",
      "Main effects training epoch: 139, train loss: 1.56594, val loss: 1.65260\n",
      "Main effects training epoch: 140, train loss: 1.56379, val loss: 1.65452\n",
      "Main effects training epoch: 141, train loss: 1.56809, val loss: 1.65819\n",
      "Main effects training epoch: 142, train loss: 1.56959, val loss: 1.67084\n",
      "Main effects training epoch: 143, train loss: 1.56391, val loss: 1.65611\n",
      "Main effects training epoch: 144, train loss: 1.56557, val loss: 1.66064\n",
      "Main effects training epoch: 145, train loss: 1.56139, val loss: 1.65606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-61aecbdc2b0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult_lvxnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_gami\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlvxnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Regression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\索信达\\代码\\lvxnn_0526\\scripts\\benchmark\\lvxnn_test.py\u001b[0m in \u001b[0;36mlvxnn\u001b[1;34m(train, test, meta_info, task_type, val_ratio, random_state)\u001b[0m\n\u001b[0;32m     38\u001b[0m                            mf_training_iters=1,mf_tuning_iters=200,change_mode=True,convergence_threshold=0.001,max_rank=3,shrinkage_value=20,random_state=times)\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr_Xi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_Xi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\索信达\\代码\\lvxnn_0526\\lvxnn\\LVXNN.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, xx, Xi, y)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mst_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[0mval_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\索信达\\代码\\lvxnn_0526\\lvxnn\\gaminet.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_x, train_y)\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"Stage 1: main effect training start.\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"#\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_main_effect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"Stage 1: main effect training stop.\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"#\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\索信达\\代码\\lvxnn_0526\\lvxnn\\gaminet.py\u001b[0m in \u001b[0;36mfit_main_effect\u001b[1;34m(self, tr_x, tr_y, val_x, val_y)\u001b[0m\n\u001b[0;32m    359\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_main_effect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_xx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_yy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merr_train_main_effect_training\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_effect_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteraction_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merr_val_main_effect_training\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_effect_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteraction_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\索信达\\代码\\lvxnn_0526\\lvxnn\\gaminet.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, main_effect_training, interaction_training)\u001b[0m\n\u001b[0;32m    189\u001b[0m             return self.evaluate_graph_init(x, y,\n\u001b[0;32m    190\u001b[0m                                   \u001b[0mmain_effect_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain_effect_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                                   interaction_training=interaction_training).numpy()\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_lvxnn, result_gami = lvxnn(train, test, meta_info, task_type=\"Regression\", val_ratio=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\lvxnn\\DataReader.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.26 MB\n",
      "Decreased by 69.6%\n",
      "Memory usage of dataframe is 0.21 MB\n",
      "Memory usage after optimization is: 0.07 MB\n",
      "Decreased by 69.6%\n",
      "cold start user: 36\n",
      "cold start item: 317\n"
     ]
    }
   ],
   "source": [
    "result_svd = svd(train, test, meta_info, task_type=\"Regression\", val_ratio=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.26 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\lvxnn\\DataReader.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.26 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.07 MB\n",
      "Decreased by 0.0%\n",
      "cold start user: 36\n",
      "cold start item: 317\n"
     ]
    }
   ],
   "source": [
    "result_xgb = xgb(train, test, meta_info, task_type=\"Regression\", val_ratio=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\lvxnn\\DataReader.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.26 MB\n",
      "Decreased by 69.6%\n",
      "Memory usage of dataframe is 0.21 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0622 09:55:02.259023  7432 deprecation.py:506] From deepfm\\DeepFM.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.07 MB\n",
      "Decreased by 69.6%\n",
      "cold start user: 36\n",
      "cold start item: 317\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n"
     ]
    }
   ],
   "source": [
    "result_deepfm, result_fm = deepfm_fm(train, test, meta_info, task_type=\"Regression\", val_ratio=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cold_mae</th>\n",
       "      <th>cold_rmse</th>\n",
       "      <th>warm_mae</th>\n",
       "      <th>warm_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fm</td>\n",
       "      <td>0.6625969191634608</td>\n",
       "      <td>0.8895530245196813</td>\n",
       "      <td>0.6329615427755786</td>\n",
       "      <td>0.8817310954424828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model            cold_mae           cold_rmse            warm_mae  \\\n",
       "0    fm  0.6625969191634608  0.8895530245196813  0.6329615427755786   \n",
       "\n",
       "            warm_rmse  \n",
       "0  0.8817310954424828  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_fm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
