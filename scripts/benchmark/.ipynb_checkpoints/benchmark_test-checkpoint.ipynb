{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0622 13:40:11.090416 24492 deprecation.py:323] From C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lvxnn_test import lvxnn\n",
    "from xgb_test import xgb\n",
    "from svd_test import svd\n",
    "from collections import OrderedDict\n",
    "from deepfm_fm_test import deepfm_fm\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from sklearn.metrics import mean_squared_error,roc_auc_score,mean_absolute_error,log_loss\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from lvxnn.LVXNN import LV_XNN\n",
    "from lvxnn.DataReader import data_initialize\n",
    "\n",
    "data= pd.read_csv('../simulation/data/sim_0.9.csv')\n",
    "train , test = train_test_split(data,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info = OrderedDict()\n",
    "\n",
    "meta_info['uf_1']={'type': 'continues','source':'user'}\n",
    "meta_info['uf_2']={'type': 'continues','source':'user'}\n",
    "meta_info['uf_3']={'type': 'continues','source':'user'}\n",
    "meta_info['uf_4']={'type': 'continues','source':'user'}\n",
    "meta_info['uf_5']={'type': 'continues','source':'user'}\n",
    "meta_info['if_1']={'type': 'continues','source':'item'}\n",
    "meta_info['if_2']={'type': 'continues','source':'item'}\n",
    "meta_info['if_3']={'type': 'continues','source':'item'}\n",
    "meta_info['if_4']={'type': 'continues','source':'item'}\n",
    "meta_info['if_5']={'type': 'continues','source':'item'}\n",
    "meta_info['user_id']={\"type\":\"id\",'source':'user'}\n",
    "meta_info['item_id']={\"type\":\"id\",'source':'item'}\n",
    "meta_info['target']={\"type\":\"target\",'source':''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\lvxnn\\DataReader.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.26 MB\n",
      "Decreased by 69.6%\n",
      "Memory usage of dataframe is 0.21 MB\n",
      "Memory usage after optimization is: 0.07 MB\n",
      "Decreased by 69.6%\n",
      "cold start user: 36\n",
      "cold start item: 317\n",
      "0\n",
      "ListWrapper(['uf_1', 'uf_2', 'uf_3', 'uf_4', 'uf_5', 'if_1', 'if_2', 'if_3', 'if_4', 'if_5'])\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 4.02581, val loss: 4.15569\n",
      "Main effects training epoch: 2, train loss: 3.86663, val loss: 4.00300\n",
      "Main effects training epoch: 3, train loss: 3.66700, val loss: 3.81314\n",
      "Main effects training epoch: 4, train loss: 3.48207, val loss: 3.63384\n",
      "Main effects training epoch: 5, train loss: 3.38250, val loss: 3.50337\n",
      "Main effects training epoch: 6, train loss: 3.28135, val loss: 3.35840\n",
      "Main effects training epoch: 7, train loss: 3.28186, val loss: 3.35070\n",
      "Main effects training epoch: 8, train loss: 3.27336, val loss: 3.36040\n",
      "Main effects training epoch: 9, train loss: 3.25283, val loss: 3.34172\n",
      "Main effects training epoch: 10, train loss: 3.15250, val loss: 3.23796\n",
      "Main effects training epoch: 11, train loss: 3.05938, val loss: 3.14667\n",
      "Main effects training epoch: 12, train loss: 3.05048, val loss: 3.13776\n",
      "Main effects training epoch: 13, train loss: 2.97453, val loss: 3.06166\n",
      "Main effects training epoch: 14, train loss: 2.90463, val loss: 2.99088\n",
      "Main effects training epoch: 15, train loss: 2.85090, val loss: 2.93330\n",
      "Main effects training epoch: 16, train loss: 2.80705, val loss: 2.88247\n",
      "Main effects training epoch: 17, train loss: 2.72197, val loss: 2.79421\n",
      "Main effects training epoch: 18, train loss: 2.70970, val loss: 2.78070\n",
      "Main effects training epoch: 19, train loss: 2.64818, val loss: 2.71541\n",
      "Main effects training epoch: 20, train loss: 2.60938, val loss: 2.68330\n",
      "Main effects training epoch: 21, train loss: 2.57306, val loss: 2.65275\n",
      "Main effects training epoch: 22, train loss: 2.51936, val loss: 2.59316\n",
      "Main effects training epoch: 23, train loss: 2.51905, val loss: 2.60367\n",
      "Main effects training epoch: 24, train loss: 2.44088, val loss: 2.52255\n",
      "Main effects training epoch: 25, train loss: 2.41554, val loss: 2.50227\n",
      "Main effects training epoch: 26, train loss: 2.38866, val loss: 2.46996\n",
      "Main effects training epoch: 27, train loss: 2.36765, val loss: 2.45355\n",
      "Main effects training epoch: 28, train loss: 2.33153, val loss: 2.41112\n",
      "Main effects training epoch: 29, train loss: 2.28303, val loss: 2.36249\n",
      "Main effects training epoch: 30, train loss: 2.26930, val loss: 2.35093\n",
      "Main effects training epoch: 31, train loss: 2.21173, val loss: 2.29201\n",
      "Main effects training epoch: 32, train loss: 2.24060, val loss: 2.32154\n",
      "Main effects training epoch: 33, train loss: 2.17058, val loss: 2.25252\n",
      "Main effects training epoch: 34, train loss: 2.18446, val loss: 2.25689\n",
      "Main effects training epoch: 35, train loss: 2.16814, val loss: 2.24363\n",
      "Main effects training epoch: 36, train loss: 2.13803, val loss: 2.21848\n",
      "Main effects training epoch: 37, train loss: 2.07828, val loss: 2.15467\n",
      "Main effects training epoch: 38, train loss: 2.10415, val loss: 2.17893\n",
      "Main effects training epoch: 39, train loss: 2.06347, val loss: 2.14620\n",
      "Main effects training epoch: 40, train loss: 2.05131, val loss: 2.12958\n",
      "Main effects training epoch: 41, train loss: 2.04399, val loss: 2.11796\n",
      "Main effects training epoch: 42, train loss: 1.99832, val loss: 2.07447\n",
      "Main effects training epoch: 43, train loss: 1.99686, val loss: 2.07381\n",
      "Main effects training epoch: 44, train loss: 1.98219, val loss: 2.05986\n",
      "Main effects training epoch: 45, train loss: 1.98538, val loss: 2.06555\n",
      "Main effects training epoch: 46, train loss: 1.93199, val loss: 2.00777\n",
      "Main effects training epoch: 47, train loss: 1.92633, val loss: 2.00292\n",
      "Main effects training epoch: 48, train loss: 1.93781, val loss: 2.01180\n",
      "Main effects training epoch: 49, train loss: 1.90558, val loss: 1.97629\n",
      "Main effects training epoch: 50, train loss: 1.89436, val loss: 1.97301\n",
      "Main effects training epoch: 51, train loss: 1.88707, val loss: 1.95539\n",
      "Main effects training epoch: 52, train loss: 1.87418, val loss: 1.95203\n",
      "Main effects training epoch: 53, train loss: 1.88074, val loss: 1.95203\n",
      "Main effects training epoch: 54, train loss: 1.84766, val loss: 1.91670\n",
      "Main effects training epoch: 55, train loss: 1.86362, val loss: 1.93316\n",
      "Main effects training epoch: 56, train loss: 1.84504, val loss: 1.91578\n",
      "Main effects training epoch: 57, train loss: 1.83871, val loss: 1.90598\n",
      "Main effects training epoch: 58, train loss: 1.83635, val loss: 1.90794\n",
      "Main effects training epoch: 59, train loss: 1.81987, val loss: 1.88301\n",
      "Main effects training epoch: 60, train loss: 1.81411, val loss: 1.87753\n",
      "Main effects training epoch: 61, train loss: 1.79435, val loss: 1.85428\n",
      "Main effects training epoch: 62, train loss: 1.80737, val loss: 1.87724\n",
      "Main effects training epoch: 63, train loss: 1.78433, val loss: 1.84476\n",
      "Main effects training epoch: 64, train loss: 1.77484, val loss: 1.83380\n",
      "Main effects training epoch: 65, train loss: 1.76469, val loss: 1.82684\n",
      "Main effects training epoch: 66, train loss: 1.75610, val loss: 1.81696\n",
      "Main effects training epoch: 67, train loss: 1.74015, val loss: 1.80136\n",
      "Main effects training epoch: 68, train loss: 1.74855, val loss: 1.80547\n",
      "Main effects training epoch: 69, train loss: 1.73357, val loss: 1.79520\n",
      "Main effects training epoch: 70, train loss: 1.74203, val loss: 1.79823\n",
      "Main effects training epoch: 71, train loss: 1.73003, val loss: 1.79278\n",
      "Main effects training epoch: 72, train loss: 1.72470, val loss: 1.77914\n",
      "Main effects training epoch: 73, train loss: 1.72740, val loss: 1.78702\n",
      "Main effects training epoch: 74, train loss: 1.71997, val loss: 1.77884\n",
      "Main effects training epoch: 75, train loss: 1.72546, val loss: 1.77572\n",
      "Main effects training epoch: 76, train loss: 1.71292, val loss: 1.77190\n",
      "Main effects training epoch: 77, train loss: 1.71444, val loss: 1.77190\n",
      "Main effects training epoch: 78, train loss: 1.71019, val loss: 1.76935\n",
      "Main effects training epoch: 79, train loss: 1.70637, val loss: 1.75924\n",
      "Main effects training epoch: 80, train loss: 1.70559, val loss: 1.76570\n",
      "Main effects training epoch: 81, train loss: 1.70424, val loss: 1.76163\n",
      "Main effects training epoch: 82, train loss: 1.69625, val loss: 1.75276\n",
      "Main effects training epoch: 83, train loss: 1.70362, val loss: 1.76509\n",
      "Main effects training epoch: 84, train loss: 1.69010, val loss: 1.74551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0622 13:40:24.459781 24492 ultratb.py:152] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-61aecbdc2b0a>\", line 1, in <module>\n",
      "    result_lvxnn, result_gami = lvxnn(train, test, meta_info, task_type=\"Regression\", val_ratio=0.2, random_state=0)\n",
      "  File \"C:\\Users\\64161\\Desktop\\索信达\\代码\\lvxnn_0526\\scripts\\benchmark\\lvxnn_test.py\", line 40, in lvxnn\n",
      "    model.fit(tr_x,tr_Xi, tr_y)\n",
      "  File \"../..\\lvxnn\\LVXNN.py\", line 176, in fit\n",
      "    model.fit(xx, y)\n",
      "  File \"../..\\lvxnn\\gaminet.py\", line 692, in fit\n",
      "    self.fit_main_effect(tr_x, tr_y, val_x, val_y)\n",
      "  File \"../..\\lvxnn\\gaminet.py\", line 360, in fit_main_effect\n",
      "    self.train_main_effect(tf.cast(batch_xx, tf.float32), batch_yy)\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 457, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 487, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1823, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1141, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 511, in call\n",
      "    ctx=ctx)\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\64161\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "result_lvxnn, result_gami = lvxnn(train, test, meta_info, task_type=\"Regression\", val_ratio=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\lvxnn\\DataReader.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.26 MB\n",
      "Decreased by 69.6%\n",
      "Memory usage of dataframe is 0.21 MB\n",
      "Memory usage after optimization is: 0.07 MB\n",
      "Decreased by 69.6%\n",
      "cold start user: 36\n",
      "cold start item: 317\n"
     ]
    }
   ],
   "source": [
    "result_svd = svd(train, test, meta_info, task_type=\"Regression\", val_ratio=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.26 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\lvxnn\\DataReader.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.26 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.07 MB\n",
      "Decreased by 0.0%\n",
      "cold start user: 36\n",
      "cold start item: 317\n"
     ]
    }
   ],
   "source": [
    "result_xgb = xgb(train, test, meta_info, task_type=\"Regression\", val_ratio=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\lvxnn\\DataReader.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.26 MB\n",
      "Decreased by 69.6%\n",
      "Memory usage of dataframe is 0.21 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0622 09:55:02.259023  7432 deprecation.py:506] From deepfm\\DeepFM.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.07 MB\n",
      "Decreased by 69.6%\n",
      "cold start user: 36\n",
      "cold start item: 317\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': True, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n",
      "{'embedding_size': 3, 'deep_layers': [32, 32], 'use_deep': False, 'use_fm': True, 'deep_layers_activation': <function relu at 0x00000299DF10D1E0>, 'loss_type': 'mse', 'epoch': 300, 'batch_size': 1024, 'learning_rate': 0.01, 'optimizer_type': 'adam', 'batch_norm': 0, 'batch_norm_decay': 0.995, 'l2_reg': 0.01, 'verbose': False, 'eval_metric': <function mean_absolute_error at 0x00000299DD933AE8>, 'random_seed': 0, 'feature_size': 1110, 'field_size': 12}\n"
     ]
    }
   ],
   "source": [
    "result_deepfm, result_fm = deepfm_fm(train, test, meta_info, task_type=\"Regression\", val_ratio=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cold_mae</th>\n",
       "      <th>cold_rmse</th>\n",
       "      <th>warm_mae</th>\n",
       "      <th>warm_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fm</td>\n",
       "      <td>0.6625969191634608</td>\n",
       "      <td>0.8895530245196813</td>\n",
       "      <td>0.6329615427755786</td>\n",
       "      <td>0.8817310954424828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model            cold_mae           cold_rmse            warm_mae  \\\n",
       "0    fm  0.6625969191634608  0.8895530245196813  0.6329615427755786   \n",
       "\n",
       "            warm_rmse  \n",
       "0  0.8817310954424828  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_fm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
